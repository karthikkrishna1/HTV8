
from collections import Counter

data_set = "we are incredibly psyched about Luke on the iPhone loped is about connecting with people on the go which is after all the main reason you have a phone we show you where people are what they're doing and what cool places are around you the orange pin up there is where I am right now and the blue pins represent my friends we make serendipity happen it's amazing how often you wrote a restaurant a couple of blocks away from a friend or stuck in an airport with an old classmate and don't know about it will show you that this is the best version of Luke that we have ever made and by far the best device we've ever had the opportunity to work with we've developed for nearly every mobile platform out there this one is the best and the most powerful so James is navigating the map just like you'd expect by pinching and dragging and tapping and we can see that there are some friends down south a friend of mine is driving across the Golden Gate Bridge and here are some friends that are varying their bias right now we can tap the map a few times to zoom in and as we zoom in we see that there's one friend very very close so we can tap on that dot and it's Erin Easter and she's only a few blocks away and so we can see what she's been doing today this is called her journal photo she's taken text she's entered all of this tied to places and shareable with any other service she'd like and the thing in blue is a comment that her friend has left earlier today so we can tap on that top entry that says back at the cutest little cafe and we can tap on it again and that photo will enlarge so that does actually look pretty cool and I don't have lunch plans today so we'll see if she's free so we can go back I could call her or I could text her we integrate with the native iPhone api's but I'll leave a comment and I'll say free for lunch if she is free then I can get directions to her in one click and one line of code another example of the power of the SDK and this is really all an example of the power of location location plus a contact list and information about cool places means you never have to eat lunch alone again or at a bad place and we think that's really cool we really do you can use loop with your friends on most other carriers or devices in the US we are the largest social mapping service in the world and very happy to announce that loop will be free on the iPhone and in the App Store at launch anyway we think this is a new era of mobile we're thrilled to be part of it thanks very much you" \
           "thank you for the warm welcome hello Toronto it's wonderful to be here it's wonderful to have you here Sam thanks for having me yeah I I was thrilled when I I got invited as the prompt engineer for this event it's super nice to do yes so let's start with a system message um uh so uh you are a CEO trained in part by open AI um and um uh please follow the instructions carefully I got this and no no no markdown necessary I got this great we got this awesome um so here's where I would like to start I have this like a really important memory to me like when I started my uh Shopify store before store I had my first sale and I remember everything about that day like literally like what I was wearing and like where I was what I ate tell me um releasing chat GDP was that such a day for you yeah it was uh yeah we weren't quite sure how the world was going to respond to chat gbt there were a lot of different opinions inside the company we knew it was good we wanted to release it because we thought it was good we had already had GPT for at that point for many months so we've gotten used to something much better we released chat gbt with GPT 3.5 and part of the reason that we decided we wanted to release it was realizing that part of our mission requires us to deploy these things gradually we want people to get used to the systems we want people to have time to adapt to think about it to give us feedback to decide what rules and regulation we want in society and so we're like well we'll put this thing out people will like it it's pretty good but we certainly didn't think it was going to be sort of the phenomenon that it turned out to be we thought that would come when we released GPT for several months later uh so we you know woke up that morning like we'd release many other products and put it out there and we were like we hope people like it um people did like it people did like it yes and by I would say two o'clock that afternoon it was clear that something big was about to happen um it wasn't clear like exactly how big because you can kind of like you know you always start with like the tech hyper early adopter crew but they were so excited about it they were like telling their friends and and that morning and then by that afternoon I was starting to hear from people who like don't normally follow Tech which is like I saw this thing it sounds wild like can you let me try it out or how do I do this um by the fifth day we had gotten a million users it kept going from there uh but but definitely that day it was like a sort of to hold how long did that take you to million users five five days five days um do you have a viral Loop in there like somewhere or like is there some viral Loop that's where invite only you know so before running open AI I ran this thing called black combinator which helps people we get started advice and I used to sit there and tell people if you don't have a viral Loop if you don't have some sharing functionality if you have something social if you don't have a network effect it is definitely not going to work and I feel very bad now because I like I clearly gave some bad advice uh but no we had none of that we put it out we put it out like not expecting this speed well no one would expect the speed of growth because it hadn't happened but we did we did not expect it you caught lightning in a bottle there like I again I I think a lot of us but our intuition support um like at least those of us who program computers we build an intuition of what computers can do and uh I remember sitting there with chat GTP um and and at some point I had this sort of realization with a friend of uh of a slack it's like hey Viet interviewing this piece of software to figure out what it can do that feels very different from anything we've ever done with something made from bites yeah look I I think it's it's so tempting to overanthropomorphize this but it's also so fun it is so fun and I I actually think that's one of the good parts about this is technology has not been that fun for a while it has not felt like a new sort of Frontier and this is like fun and it's certainly a new frontier um but it's very tempting to anthropomorphize it and I think we we have to like figure out a way to still have the fun but remind people that this is a tool and not a creature um but as a kind of really powerful interactive tool it is totally fun to sit there and explore the edges of it um a lot of people have done that there's there's a real talent for people who are good at this and they found amazing amazing things in a lot of them um I remember speaking of like early on in those first few days uh I was like sitting at home late one night kind of like catching up on reading the internet um all of it yes all of it um but but it was just incredible what people were doing and what people were finding and and the kind of creative power of humanity that these tools are going to that already are unleashing it's wild to watch yeah profound I remember Karen and I have a like sort of playing around with it and um first I asked it to do a guessing game just like guess the number I want you to find between zero no 100 and it kind of got itself like it just didn't do it well and I remember Fiona saying well why does it not understand the strategy here and asking it if it knows the strategy and then at the end it it wrote out how it should approach it and then can we play again and afterwards it approach of complete correct strategy and it's like something changed in that moment it's like oh what like this is different and and you know what we lots of us had access to g2b3 before yeah and of course it's a testament to the building of Brilliant Minds and open their eye to get it to this point through tweaking so I think there's a really there's several super important points in there um I'll just highlight a couple one is that we not open AI but we the field we Humanity it's been this like culmination I think we should like be collectively as proud of this as we were for the moon landing um after decades centuries of scientific and technological progress we have figured out a computer algorithm that can really truly know tricks no no sleight of hand it can actually learn as you saw in that and we can argue about what the definition of learn means but it's enough that it's useful and it's enough that it's like fulfilling this role for all these people and it gets predictably better with scale so those are two things taken together that are a profound thing for what's going to happen in the coming decade for Humanity I think it's going to be fantastic I think we're already seeing how people are using this to learn new skills uh to deliver sort of all sorts of new creative Services just got to meet with a bunch of people building on it in Toronto um but this is going to be a very different world and if you look at the progress from even before gpg3 which Toby just mentioned but gpt2 in 2019 people tried it and said this is like a dead end direction scale that up gpp3 people are like oh okay GPT 3.5 was like finally usable and gpt4 people are building entire companies around gbt five six and seven I think will continue in future years on on this trajectory of really increasing the utility they can provide um and this is like a a big new exciting thing to have in the world it's a it's like all Computing got an upgrade um you mentioned uh fourth and then went to five six seven um let's talk about like you you did a very carefully crafted brilliant um post right around the with the release of gtp4 and um it's going in a lot of details amongst those um you are describing that um it is quite predictable very early in the process of training a model how smart it will end up which is that feels like a profound and very overlooked kind of detail of this announcement the g2b free 5 seems to manage to pass the bar exam at like the bottom percentile gdp4 at the 90th percentile like the flying colors really um but the deduction here is you also know how to leave the percentiles and and make something that is um smarter or would be 100 offered by exam and other tests how how do you make a decision about when to start another training run and how to load it up and what to aim at here because we are like dealing in a fairly narrow spectrum of of intelligence percentiles within the human experience at some point we will have the tools to go beyond it yeah when is it time for that when is the time for that yeah or how how should we now actually not when it's the time for that how should we make the decision about when yeah together so let me touch on a few parts there first of all this I think we'll look back at this period like we look back at the period where people were discovering fundamental physics I think the fact that we're discovering how to predict the intelligence of a trained AI before we start training it um and that there is something something close to a natural law here and we can predictably say this much compute this big of a neural network this training data this will be the capabilities of the model now we can predict how it'll score on some tests what we're really interested in which gets to the latter part of your question is can we predict the sort of the qualitative new things just the new capabilities that didn't exist at all in gpt4 that do exist in future versions like gpt5 that seems important to figure out but right now we can say you know here's how we predict it'll do on this eval or this metric and and I really do think we'll look back at this like we were all living through one of the most important periods of human Discovery I think this will be that that big of a deal in terms of how we think about when we go beyond human intelligence and and I don't think that's quite the right framework because it'll happen in some areas and not others you know already these systems are superhuman in some limited areas and extremely bad in others and I think that's fine um I think humans will have a role Toby and I were talking earlier this analogy that like everybody's going to be the CEO of like all of the work they want to do and they'll have tons of people that they're able to coordinate and direct and sort of provide the taste and the feedback on um but they'll have like lots of agents for lack of a better word that go off and do increasingly complex tasks I think it's going to feel like this gradual thing it's it's these these AIS join Society they join the workforce it's not even like we feel like any one instant any single AI is way more powerful than a human we haven't made a decision we don't even make a decision there it's that we have you know eight billion humans and we have 8 billion AI workers that kind of just exist in society and give us all a lot of Leverage so if I run a small business um hi let's let's go just go in this future and let's talk about it like if if I'm a small business owner I might make the decision to hire Fred 1.1 joining my Google meets meeting and then afterwards doing a write-up and doing some accounting for a couple of hours um is this like is this a way to think about it are these team members that uh with presents and yeah and permanence I think that is definitely one way to think about it it's like a sort of fully remote virtual employee and that will have a lot of impact because we can have a lot of those I think there's another way to think about it which is when the AI systems can either semi-autonomously or just by helping us a lot really discover new science and if the rate of scientific progress that Humanity makes increases by a factor of 10 or 100 or a thousand in a year that somehow feels different than just a bunch more remote employees are you talking the on on the doing science part I think I mean in AI there's no other field that has ever existed or will ever exists who have a goal post keeps moving quite as much right um I Asimov books tend to people tend to identify that's something there's no AI behind some actor because AI could never be creative or could never be funny or something and so so the goal posts keep moving but with that in mind to do original science that feels like one of us things someone might offer as a point at which AI has transcended into something else look certainly by the time AI does original science we'll move the goal posts again and say well that just wasn't that impressive in the first place um if you look at the prediction from maybe 10 years ago maybe even five I think most experts would have say first AI comes for physical labor it's going to drive trucks it's going to work in factories then it comes from the sort of easier parts of cognitive labor then it comes from the stuff that's really hard maybe it can be you know maybe it can write computer code someday maybe not and then maybe someday in the distant future but probably never it can do creative work and of course it's gone the exact opposite direction uh every almost everybody predicted this wrong but the fact that it can do this this sort of creativity and the fact that it can use code to verify things actually gives me hope that we may have an AI that can do science before we have that factory robot that we can do everything else so I think intuitions here are just difficult it's fascinating to unwind a little bit the the steps of training office models like we obviously train them on reading all of Internet but there was a step function increase around teaching them to code right like at some point the models got trained on code and their ability to reason became significantly better which in my experience by the way is the same for executives that I work with so when they learn to code their number got trained on code are much better at reasoning I've observed that's a good that's a good Insight yeah yeah that makes me happy to hear so um and uh so now recording is part of a training and we've just kind of figured out something what else is out there like what else other experiences that children go through which would be amazing to expose to these models to make them more human-like so I do think coding is pretty special um coding has some nice structure to it you can run the code like an AI agent can run the code and look at the output and sort of say this is right this is wrong there's like debugging messages along the way there are a lot of things about coding that I think are particularly great modality to train these models on um but that won't be of course the last thing we train on I'm very excited to see what happens when we can really do video there's a lot of video content in the world there's a lot of things that are I think much easier to learn with video than text there's a huge debate in the field about whether a language model can get all the way to AGI can you represent everything that you need to know in language is language sufficient or do you have to have video I personally think it's a dumb question because it probably is possible but the fastest way to get there the easiest way to get there will be to have these other representations like video in these models as well again like text is not the best for everything even if it's capable of representing everything fundamentally these models are just sort of like bits of data in bits of data out and it turns out you can represent a lot that way but we should still try to figure out the best representations you've talked a lot of the questions in your interviews are around this safety aspects and I don't think we need to argue there's lots and lots of content of your opinions there um it strikes me about the work we are doing right now around the large language models um is of unbelievable utilitarian value to people uh like we can build it it's I think some people call it the end of a beginning um for us um for software at least and maybe even Beyond because we now can fold software and other kind of things that we've created over the last 20 30 years or since touring really like like integrate them into life in a way that's very lifelike huge value but it's not AGI as a tool yeah it's an augmentation of what the experience in the same wave a cell phone is there's a lot of to be made of at some point like emergence just strikes and then it becomes super intelligent as if you know like I don't know a Sandbox in a yard could spontaneously turn into a nuclear warhead and so um give me your take on like how can we like how do we set up the moments right now in such a way that we are going to get to the most optimistic outcomes that we all want to have happen because like a lot of us really want um AI definitely utiliteria value on maybe AGI if you can attain it in the timelines we are on because that's the most awesome version of planet Earth clearly yeah I'm really happy you asked the question that way I'm uh it's a little bit exhausting having to always talk about only the downsides and not to get to talk about the upsides too and I don't want to make light of the downsides because I think they're incredibly serious but we have a lot of people doing great work to figure out we're going to successfully mitigate them the reason that this is all happening the reason that we're having this debate the reason that people like people love this stuff and they love it because it's providing them real utility and that that doesn't come along too often we don't we don't get like a real new tool in the toolbox that fundamentally reshapes what we're capable of doing that often maybe the cell phone was the last one um I think this will be bigger than that yeah but it will at least be a similar magnitude and and I think the way we get to this awesome outcome is to unleash the creative power of the world and I think it's really happening I think it's at this point it's much more of a don't screw it up then we have to get it launched it took us a long time at open AI to figure out something that was going to work before we got to the sort of language model World um which was only four years ago that we figured that out we had a lot of like dead ends or bad paths the field did too you know AI winter is sort of this joke because it always was the at winter um but now I think like the revolution is launched and people are going to figure out how to integrate this into many aspects of society and significantly improve what we do um I'm I'm so excited about everything happening I like watching how kids use like when I was a kid we used to just go to these Wikipedia rabbit holes and you did eventually learn what you were trying to learn but it was like kind of a long and painful but very interesting process and now you just ask a language model and it teaches you whatever you want and you ask follow-up questions and if you don't understand something it knows that you don't understand it and explains what's different um you hear from doctors who are saying like I'm never going back I'm never going back to a world where I try to make diagnosis diagnoses without first inputting the symptoms of test results whatever um you're from creative people who are like this is now an indispensable part of my creative workflow I'm never going back and I don't know I'd say like most of the startup energy most of the developer energy I see is now trying to figure out what to do with these Technologies this is going to permeate everywhere I think it'll happen fairly quickly and I think it'll be great the I think um like what we want to do is like set this up well right now like like if you ever watch a movie like like it's like 40 50 years old you see like maybe the parents smoking in front of a car with the kids in the back you know and that seems insane now but that was perfectly normal back then right um so it's a little bit passovers ends up like um working in funny ways and and and and and opinions um evolve I think a better question is like think about the future and like figure out in which ways are we making mistakes right now and um what should be changed for the maximum like and this is maybe Beyond AI um what is what is lacking right now to steers to the um to maybe even the general recognition that the world is so much more awesome than I think we all could have possibly imagined knowing for well around the margins there's lots and lots of problems I'm not making light of those but boy is this like a Sci-Fi novel that's just like sometimes sounds actually like a bit on the nose right like we have cryptocurrencies flying around the world we have Global pandemics that make us lock up and like actually work in unison on biohacking to fight them back and then we have we have conversations with um a model that you put out there in the world and it's 100 million people interacting with it and not just the people in the sort of glass Towers in downtown like places like this New York and so often it's everyone yeah and it's a shared experience for first time again and a while after a lot of theater Bubbles and that's really really meaningful I think so um I've supplied a lot there the um question to you is like where what other edits you would make to the way people look at the word right now I I think we have lost our Collective sense of optimism about the future for good reason in some cases but I think all of us should act as our duty to bring that back I think we have lost a belief that the future can be radically better than than the current world I think a lot of people assume it's going to be worse again for good reason the only way that I know to return to that sense of optimism and that sense of growth is to use technology to create abundance this works this is like a long-term sustainable strategy as far as the systems that enable that like the social systems liberal Democratic Values the governments we have in much of the world today they enable the scientific and technological progress but that is the only thing that drives real sustainable long-term economic growth and if you don't have that the future does not get better and I think we have lost a belief that we can still do that we had a great run in society for maybe like you know 150 years and then it kind of ended a few decades ago and it's been hard to get it back but technology that can deliver abundance the technology that can deliver like a lot more a lot higher bar for quality of life I think AI is one of these big ones energy is another the stuff that's happening right now with bio is amazing uh there will still be a lot of it's like seems like very human nature to worry a lot about the future and to sort of feel a little bit zero-sum but the more we can get out of that the more we can just say like hey there's going to be plenty to go around the pie is going to get much bigger every year every year is going to be like dramatically better than the year before um and looking at technology is the only Vector to solve that and is the sort of like moral obligation of all of us to push forward I think that's the path forward I love that it's this is perfect the a lot of these advice about this um have really really benefited one way or another um the economically most privileged one billion people on cloud Earth which is an incredible story because up any point before the enlightenment things have definitely not helped the most people they had they had to pay a few people what can you do to make sure the next like what we're building now is gonna help the other seven billion people too I I think I think that's really happening I mean the the version of this I think about the most is AI but I've heard about this in other Technologies too and I think pretty compelling answers that one of the things that is powerful about this sort of chat interface of chat gbt is that small children can use it old people can use it people who are very uncomfortable with technology can use it people that have a 20 Android phone can use it and get access to the same thing um I think it's a fundamentally equalizing technology in a way that not everything has been there's of course a lot more we have to do to stick on the energy example I think driving the price of energy down by a factor of 10 or 100 will help the poorest 7 billion more than the richest 1 billion a lot and you're working hard on a solution to that too can you share that um well like just uh yeah that was a milestone recently um yeah this company called helion uh that I spend time on just signed a deal with Microsoft it was the first it is the first fusion power purchase agreement they'll begin delivery in 2028 still small scale but the fact that I think we now see a path towards delivering Fusion Energy and the whole goal of the company at this point is no longer the physics and the and the r d but how can we make enough of this energy for everyone on Earth at current needs and how can we bring the price down ambitiously by a factor of 100 at least by a factor of 10. um and you know Fusion has been like 30 years off forever but now that it's only like five years off that's a little better and I think we can figure out how to do this at mass mass scale it's like hard supply chain challenges but those eventually get solved and if we can just figure out how to build a factory that's like putting out two 500 gig 500 megawatt generators a day that'll make a real dent it's a tantalizing vision for a future we are like all problems in the world can be reduced to energy problems we are every war has been fought for usually resources that are Just Energy in the ground or land land use it took me a long time lot it took me a long time to understand how important energy was to everything yes I had like totally taken it for granted um but the more you think about it the more you realize that like that is the Crux of so much yeah yeah a dust Revolution on steam power we um you need to excuse Cola they found oil afterwards and build that economy then we did nuclear and built the nuclear economy when everyone told us to stop doing that and go back to that was a big mistake the place you're going to is a economy that needs uh fusion and uh delivering that is going to be making um all this little side quests and silly and Petty problems that occupy people day to day um seem very trivial if you can do it so um thank you for uh for investing in in this and like huge progress along those lines which is like the fact that you saw or you and helion signed a energy delivery agreement in five years the penalties for non-delivery is a amazing sign because if it's and one thing companies tend to be good at is not signing things which are going to hurt them later on so they're very good Sam thank you so much for joining us today Toby thank you so much let's give these two gentlemen a round of applause thank you thanks for doing that" \
           "good evening ladies and gentlemen welcome to the economic Times conversations today we are delighted to host Sam Altman CEO of open Ai and the founder of chat GPT Sam is one of the most influential voices in Silicon Valley and now the center of all conversation around AI in conversation with Sam will be satyan gajwani Vice chairman of times internet Limited but before we begin a note of thanks to our partners presenting sponsor TCS co-sponsor OnePlus powered by partner Lenovo education partner SDA bocconi Asia Center digital partner land View and telecast partner ET now this event is being broadcast live on etnow and also streamed on our app and website economictimes.com may I call upon stage Siva CEC of bccl to deliver the opening address good evening and welcome I always had wanted to write poetry but soon not like us so I got this stage chance to speak at the stage today so I'm going to read out a poem in the Realms where dream unfold amidst the Wonders yet Untold they say it's a vishnadi bold Sam Altman his history to be told to Sam's Vision gen AI did thrive from Deep neural networks it allows a symphony of intelligence nobody knew and so this saga continues to unfold Sam Altman and Jen AI Brave and Bold a tale of innovation Untold and true a testament to what Humanity can do well none of you seem to appreciate this perfectly composed and rhyming poem this is the power of human intelligence and I am sure you already knew that this is not from my heart but AI generated to chat GPT so this perfectly composed poetry was generated by Chad GPT I am sure you have all read about the student who was caught cheating on an essay about Shakespeare's 12th night because he forgot to remove the line I am sorry but as an AI language model I am not able to complete this assignment so the question before all of us this evening would machine algorithm and AI Trump human emotions intelligence and irrationality in the future it is no surprise that the one the who's who of the business world are here today to listen to the man of the moment himself it is a testament to incredible technology Sam what you have built one that resonates with everyone from school kids to CEOs closer home to our new own newspaper we have seen a number of stories in the recent past about generative AI it has sky is located since chat gbt arrived on the scene no company wants to miss out on the power of generative AI and this Zoom the packed Hall is a proof of that businesses governments and even individuals clearly want to get smarter more efficient and more AI enabled what chap jpt has done is that it has made artificial intelligence accessible and into something that isn't intimidating or technical but enjoyable informative while also being resourceful and entertaining with over 100 Millions monthly active users it is the fastest growing application in history today even as we comment all the incredible Innovations and observe the sudden increased competition there are some things we can't ignore it is true that the very pressing need for accountability responsibility and regulation something Sam himself has been very vocal about India is uniquely poised because it is the largest most diverse demographic of the world a technology like this can be both transformational and also desertive India has the formidable challenge of providing jobs to Millions entering into the workforce every year and as per Goldman Sachs research which suggests that AI can replace the equivalent of 300 million full-time jobs our own Publications have reported that the challenge challenges that come with generative AI in the realm of fraud scams deep fakes misinformation manipulation and more equally it is possible that the power of AI is harnessed for the good of humanity for the even for the moment even amidst all these risks we have much to celebrate and we shall thank you for being here Sam it is Delight to host you maybe the poem was from chat GPT but rest of what I spoke is from my heart and no matter how much technology progresses my firm belief is that human emotion and intelligence will always Trump machine algorithms or to you Sam and satyan thank you is this working hi everyone thank you for joining and of course the man of the hour Sam thank you for joining uh so what we'll do is I want to ask Sam some questions myself and then after that we'll open it up to a broader set of people so everyone can can have some time you know Sam just before we start I want everyone to understand your story because you have such an interesting background in the tech ecosystem you know help us walk us through from graduating stand we're not not graduating joining Stanford dropping out Running Y combinator running a different startup before that and now running open Ai and a number of things just help us understand how you came to where you are right now yeah so um I I started at Stanford where we met and I found I mean I was already in love with computer science but I really fell in love with it once I got there uh I actually went to study AI but at the time AI was really not working at all in fact very memorably one of my professors said the only sure way to have a bad career in AI is to work on neural networks we've decided those don't work um and so I got kind of discouraged and I started a company uh that was a great experience the company didn't work out that well but I kind of like learned about startups and thought they were a very powerful force and something I was very excited about so I then ran YC for a while and while I was doing that I got newly excited about the idea of startups that take on hard technical challenges and I sort of thought it was curious to me more people weren't doing that um it seemed like a really valuable opportunity with some other people started openai as one of those examples and many other things which have gone on to be pretty exciting but really fell in love with openai once it seemed clear that we were really going to have a chance at making true general purpose AI like a system that could do what a human can do and contribute new knowledge to society I got like really excited and wanted to go work on that and so stop being an investor and now I do that amazing so so first of all what is open AI is it just chat gbt are they the same thing are they different just help us understand what the company does we are a company that is doing research and deployment to try to figure out how to build AGI and how to responsibly deploy that into the world for maximum benefit so this is unlike other Technologies well other Technologies are like this too but this is a strong case of a technology that on the one hand is the most exciting most promising coolest thing I think that Humanity will have yet built we can cure all disease we can give everybody a great education Better Health Care massively increased productivity huge scientific discovery all of these wonderful things and we want to make sure that people get that benefit that benefit is distributed equitably and on the other hand there are the obvious concerns about the power of this technology used in in a negative Direction and so we want to be a force to help manage those risks so that we all get to enjoy the benefits Chad GPT is definitely what we're best known for so I guess they're sort of synonymous at this point but openai is really about this quest for AGI so help us understand I mean all of us have played with it right we have poems getting written by it we've all asked it fun trivia questions tell her in answers but help us understand you you uh you know without a doubt have a better understanding of how it's getting used all around the world in all sorts of different Industries vocations reasons talk to us a little bit about some of the most interesting things that you've seen like for example what's the most surprising use case of some of the technologies that you guys have built that you've seen recently so the main thing I would say that's interesting about it is its generality there's a lot of other systems that can go do this thing well or that thing well or this thing and you know many cases better than Chachi PT some not like there's not probably not a AI that can write a better poem or whatever but you know other categories you could find something that's maybe better but the fact that this one system is truly general purpose and can do so many things means that people are integrating into their workflow as a very powerful tool and so the same thing that can help you write computer code one of the areas that we've seen the biggest impact is what coders are using this for doubling tripling their productivity um you know there was a paper that just came out that when Italy temporarily banned chat gbt developer productivity like fell in half on like a fairly big study and but it can do that it can also you know help you find information it can help you write a poem it can help you summarize documents it can translate things and people are using this which we hoped would happen as this sort of super assistant that just makes them more and more productive and it's that generality that I think is the coolest part so with with so much ability that maybe even you guys haven't even thought about how people are using it when you when you developed it and launched it um I'm sure you've seen a lot of interesting use cases right here out of India itself can you tell us something or just give us an example of something you've seen that's really inspired you that you've seen come out of the Indian market so India has been a country that has really truly embraced Chachi BT um in a way maybe you can tell me why I'm sort of curious I'm hoping to learn while I'm here we're very delighted but uh there has been a lot of early adoption and real enthusiasm from the users one of the very earliest things like in the first weeks of launching chat gbt we heard about a farmer in India who wasn't able to access government services and Via like church BT hooked up to WhatsApp and some sort of complicated way was then able to and I was like that was like one of the early things we're like huh we did not think that was going to happen and and just to you know expand on it so so what I've understood about open AI is chat GPT is one implementation of the things you've built but you have capabilities to real time translate uh to transcribe audio into text and and are you seeing people use these in combination in ways that are surprising well we recently launched an iPhone app that has uh speech recognition in it which is that's hooking up two of our models together and people love that but the the main point that I would like to get across is none of the current systems really matter uh like we're going to look back at gbt4 and you know I don't know if any of you have like picked up an iPhone the original iPhone in recent years but it's like wow I cannot believe we were excited about this each pixel is like that big you know it's it just feels like this like incredibly Antiquated thing um the curve here is going to be much much steeper and what the systems are going to be capable of in the not distant future we think is going to be very dramatically different so this is like a system that I don't even know what the right this is like the old first like grayscale Nokia phone that looked like a little candy bar and the iPhone 14 is coming so what I would say is it's a mistake to get too focused on the current systems their limitations their capabilities the impact they're having the thing that matters here is we are on an exponential curve truly um two two big Miracles I think in the field number one we have an algorithm that can genuinely truly like no tricks learn and number two it gets predictably better with scale and that we're going to look back I think on those two realizations as a turning point in human history when you put them together but what it means is that the rate of progress in the coming years the capability is going to be significant so it's totally cool that Chachi BT can write that poem when a future system can like cure all disease or help us address climate change or radically improve education uh or make us all like 10 or 100 times more productive at what we do that's quite impactful it's amazing now let's flip to the other side of this because there's no doubt there's incredible power in this technology and you know with that comes challenges I want to play a clip uh maybe you guys can put on a clip of something I recently heard Sam speak somewhere and we can talk about it a bit could you uh play the clip please hi my name is Sam and I'm happy to be here today thank you all for joining I also wanted to say that the gentleman on stage with me is incredibly good looking and I also want to say that you should be very careful with videos generated with artificial intelligence technology okay so you didn't say that recently clearly that was just a ploy here but and thank you by the way it was very totally agreed um but but nonetheless I think it raises a real question right when you know this video if you look closely you can see the lips aren't perfectly synced but like you said this stuff is only going to get better and exponentially better fundamental questions are on authenticity what's real and what's fake how do we handle that yeah so that was like deeply in The Uncanny Valley it's very strange to watch but we're not that far away from something that looks perfect and there's a lot of fear right now about the impact this is going to have on elections and on our society and how we ever trust media that we see I have some fear there but I think we're actually gonna when it comes to like a video like that I think as a society we're gonna rise to the occasion we're going to learn very quickly that we don't trust videos unless we trust the the sort of provenance we'll have techniques like watermarking detectors more than that I suspect at some point if people are saying something really important they'll cryptographically sign it and you know web browsers or phones or whatever will build in some ability to say okay this is authentic but that part we can that part we can all uh adapt to like we did this with Photoshop there was a period of time where people thought if you see an image it's got to be real we learned we're like okay you know that thing is Photoshop did happen quickly videos like that that'll society would build antibodies quickly but there's a related thing that I think is getting discussed less which is not the ability to generate mass media like that but customized one-on-one interactive persuasion and I think people are going to be able to create AIS that are very good at this so it won't just be like you know I'm watching a video of you but it'll be like I'm chatting with you back and forth and it's like the most interesting compelling conversation that I've ever had that's like affecting me in ways I don't know about and that's a new thing that's different than just generated media again I think we'll find a way to build societal antibodies to it but I don't think it's discussed as much and it's going to be a challenge I also want to talk about jobs because the the natural fear is AI is going to make us redundant particularly in markets like India where we have so much of a Workforce and a lot of it is oftentimes doing somewhat wrote work should we be worried about this I mean does this affect societal disruption on employment and capitalism and all the things and how we've been running I mean to some extent yes every technological Revolution leads to job change and this will be no exception um I guess three thoughts number one job change itself is fine uh you know if you kind of look at the history of this in two generations we can kind of adapt to any amount of Labor Market change and there's new jobs and the new jobs are usually better and that's going to happen here too some jobs will go away there will be new better jobs they're difficult to imagine as we sit here and dream about the future it's going to look like the thing that might be different about this is the speed with which it could happen and I think it will require a change to the socioeconomic contract and the way governments think about this if it if it happens at a very fast pace the second thing is it's not going the way people predicted so far and I don't think it will in the future so the current systems are actually not very good at all at doing whole jobs they're very good at doing tasks and so the the nature of the job if you're say a computer programmer to stick with that example shifts to you kind of like manage a team of extremely extremely Junior developers that can only do one one minute task at a time and then someday they'll do 10 minute tasks and then they'll do an hour task but you'll still have to think of like the house is all going to fit together what I want to build and you know maybe eventually it learns that too but this idea that instead of replacing jobs it's making people dramatically more efficient and there is such a demand to overhang in most places you know if we can overnight make the world create 3x more software because we make every software developer three times more efficient that is not nearly enough that does not nearly fulfill the demand the world has for software and I think we'll see that in many other places um so another example of this is that the consensus not the consensus the like absolute belief of experts around the world 10 years ago first AI is going to come replace the physical labor jobs so truck drivers Farmers Factory workers real trouble then it'll come for the sort of easier kinds of cognitive labor then maybe eventually like computer programmers even a mathematician and then you know way in the future or maybe never because maybe it's like magical and human the creative jobs and of course we can look now and say it appears like it's going exactly the other direction but that was like really non-obvious certainly to us we started thinking we were going to build robots and it's still in some deep way sense to me seems like it should be much easier to make robots than it is to make gbt4 but here we are I think with other job impacts it's just gonna be surprising but I think the world will get way wealthier you'll have a productivity boom and we will find a lot of new things to do you talked about robots and you know we've talked about sort of the the real practical likely disruption that we're going to see because of AI but we also have to talk about that one percent like Extinction risk or that robots are going to come and take over our lives how do you think about that I mean you have actually been probably more so than the average person um cautious about this and and for us we kind of think of it as sci-fi kind of like in the in the realm of not really realistic but interesting to talk about but I think you would say it's it's something real that we have to think about for sure like I want to be super clear I don't think current systems are dangerous I don't think there's any way that gpt4 like causes an existential risk to the world but people are very bad at thinking about exponential curves and gpt10 may be a extremely different thing given the importance of getting this right even if it's a one percent chance uh I think putting a lot of effort into thinking studying like how we align an AGI how we design Safe Systems at this kind of scale is super important um and starting that early is really good I think we can totally manage through it I think we're developing techniques to mitigate it this is really why we started the company this was like our initial focus and still is our most important Focus um but yeah we need to address this so is there like a power switch in the back of your office that nobody knows about where you can just like the Jurassic Park that giant yeah it has to be big and dramatic but you pull this big thing and it shuts down all the systems if we need it exactly like that okay good okay I'm glad I feel better now okay and it works even if you're traveling right I mean yeah okay anyways um so let's talk about regulation because again I think what's really unusual is this company is a few years old but really for the for the consumer it's like less than a year old because a chat gbt and yet here you are traveling the world meeting leaders globally to talk about the importance of Regulation and not only are you doing that you are probably one of the most vocal people saying we need it and not one of those you know we'll regulate ourselves leave us alone type of things you are saying governments need to step up understand this and get involved this is very weird this is not like how most startups operate what's going on well again we started the company because we were nervous about AGI risk before you were really before people even talked about AGI um and now I think part of the reason we deploy systems is so that people confront the technology feel it understand the risks the benefits and now a lot of other people are also very excited but sharing the concern I think this is a special moment where the globe can come together and kind of get this right and we certainly would like to try to do that let's talk a little bit more about AI in India because it's so unique for us and there's so many interesting use cases that are very India specific you know one of the obvious questions we think a lot about are languages right India has one of the largest depths of languages hundreds of languages in the country now ai is by and large trained on what's publicly available what's available on most of the internet which is you know inevitably going to be mostly English probably a lot more Western focused in terms of just the sheer quantity of stuff that goes into training how do you think about biases how do you think about inclusivity how do you think about multilingual countries like India and making a product that's relevant that's useful not just for all of us fancy people sitting in Bombay and Delhi but for you know everyone in the mass of the country yeah it's it's super important to us uh we've had a big step forward from GPT 3.5 to 4 at non-english languages so gpt4 is is pretty good at say the top 20 languages and okay at maybe the top hundred we will be able to push this much further uh you know it's challenging for us for very small languages spoken by you know only a few tens of thousands or hundreds of thousands of people that that's difficult but the systems are fundamentally going to be very good at this I think and it's important for us to do now as you were saying it's not just the language it's also the history the culture the values and we want the entire world represented in here there will be some areas where the world's got to agree on like here the sort of global bounds of the system but mostly if you want to use it in the US or in India that can be under a different legal framework and then in different parts of the culture in each Place it'll it'll be very different and I think that should all be represented in there we recently launched a new program to give out grants for people that want to run experiments of the ways we can do this the way we can collect this but we we really really want to interesting you know India has been particularly unique and successful globally at building a lot of the underlying technology Stacks to support new innovation in digital with India stack UPI Adar things like this do you think India should build its own llm AGI AI engine you know in some sense should we think of this a little bit like nuclear technology where every country should be building its own capabilities and you know a little bit more nationalist in the way we think about this I mean how do you think as a country we should think about AI as something in a sovereign sense first of all it's super impressive to see what India has done I think in a way that really no other country has uh with these sort of saying we're going to do National technology really well and like make it a really like a National Asset in terms of AI strategy I think there's like a lot of things that can work I think this question of sort of AI Serenity none of us have an answer to yet feels like it's gonna be at least somewhat important but the main thing that I think is is important is figuring out how to integrate these Technologies into other services and that is an area that I think governments are behind on and don't have the answers to yet um but you know I think like hopefully we all start to use llms to make government services way better and both from like how do I enroll in this program to like how do I get better health care but but if you're in the Indian government should you be like we need to set up a team of crack Engineers to build our own open AI I mean is there a concern for us to say are we depending on like for fundamental infrastructure are we depending on something that's not owned by our country yeah I think it is good to have certainly some sort of AI research effort what exactly that should do you know should that be training ground up llms should that be pursuing new research directions should that be focused on fine-tuning open source projects I think there's a lot of options there and there's I don't yet like have conviction on the right answer but some you know nationally funded AI effort feels like a good idea one of the things that I think is so interesting is that open AI straddles this line of being a non-profit and a for-profit and I don't know how I don't know if I fully understand it I don't know if many people do I know you've raised money from investors and Microsoft is definitely one of your shareholders uh when we think about it is it do we think of open AI as something that's here for society to do societal good is it here to make money for its shareholders is it both what happens if those conflict we're definitely here for the societal good like that's super clear and that's why we put up with all this complications can you help us understand what exactly does it look like so there's like a non-profit that has a board that governs this thing that we call a capped profit where our investors can make a certain return um but if we ever need to make a decision that is in favor of societal good but not in favor our shareholders were set up to do that and one of the most controversial things I heard was that you don't own equity in open AI why is that what's going on um I mean it started just as like sort of this Quirk of our structure where we needed non-conflicted people on the board who didn't have Equity a certain number of them certain percentage and then I kind of just like never got like I forget about it until it comes up in something like this but it's I don't think it's like a particularly noteworthy thing like I made a ton of money early in my career I actively invest so I expect to make a ton more I get far more value from even like personally selfishly speaking I get far more value from like all of the other sort of benefits that come from running openai a very interesting life than I would for more money but most of all like I just believe that this is going to be the most important project of our time and I'm super grateful to work on it if you need me to like send you reminders to to keep up on it I'm happy to do that just let me know yeah so look a lot of people have flown in here from all around the country to come hear you and while understanding all this theory about AI is cool help us do our jobs better I wanted to put you in a couple roles and tell me okay you are now the CEO of a hospital in India what should you do and not theoretical go hire a couple people like tell like help me do my job better be my AI for a second here one of the things that we have heard from a lot of doctors uh is that they're they're using chat GPT with gpt4 to help come up with new ideas for tricky cases so you know input the symptoms maybe the test results say I can't figure this out what are some ideas for the differential diagnosis and in many cases getting great results back awesome now let's say you're running a bank what do you do this is like rapid fire we're all taking notes to do our jobs better here um like a sort of traditional like bank branch on the street that kind of Bank not like an investment operation yeah like a bank like a traditional bank that issues credit cards and checking accounts and all that stuff um foreign I think I would try to just like on a very brief little side journey of my career I once like helped build a mobile banking app and on the side no no it was like it would okay yeah whatever um I still think the consumer experience of banking is terrible and could be a lot of it could be replaced by like chatting with an llm it's interesting let's say you're running a university you're uh you're a Chancellor I mean we've all seen how chat gbt can definitely affect the education experience now let's say you're running a university yeah that one I think is pretty clear I would just like go redesign the education experience I would have the equivalent of like personalized tutoring interactive textbooks um I would like I would integrate it into like all parts of the learning process now now just totally theoretically let's say you're running like a large news media company in like a market like India like just as an example what would you do and let me just get my pen real quick but uh yeah what would you do just tell me um one of the things that you know there's been a lot of controversy about whether this is going to be good or bad for the publishing industry in news in particular one of the things that we've heard from journalists and reporters who are actually using the the product is that it helps them do the boring parts of their jobs better and they get to spend more time reporting talking to sources thinking of ideas and so I think I would just like encourage everyone to just start using it and now let's say you are the ministry in India responsible for overseeing technology AI Etc um you know what what would you do in that situation like what would you be doing today as a regulator I would say you know we have the G20 coming up India can play like a huge role here in global conversation about what this sort of international regulatory thing might look like and we are going to really focus on that between now and September and make sure we prioritize that can you tell us something that you haven't told other people about what's coming from open AI like maybe just some Insider information that we could use in some form or you know we kind of tell people what we're working on like it's gonna get smarter it's gonna get multimodal we're gonna try to like teach it to generate new ideas come up with help us like discover more new science we're going to reduce hallucinations we're going to give users like more control so no one feels like it's biased or at least it's biased in the way you want it to be biased we don't have like a lot of secret plans here I think always as a company to our strength and weakness we just sort of say what we think and what we're going to try to do it's amazing now the one of the most amazing things about you Sam is that you are running what is going to be one of the most impactful companies in history whenever people say impactful they know they they leave out whether it's going to be a good or a bad impact that is a very purposeful leave out because we don't know right but it's you you're going to shape the world with this we know that and this isn't your only job as I understand or maybe it's not really my only like operating it's the only thing that I'm like can you tell us what else you're doing that's like exciting you or motivating you outside of an open AI sure you're side hustle sure if we put it that way um I think we're gonna get nuclear fusion to work in the next few years at and importantly not just as a scientific demonstration but as incredibly cheap energy and at global scale so I think other than AI if you could do one thing that would like really help the world get richer increase the quality of life it's very cheap energy I think there's like a huge historical correlation there and I think we've all like lost sight of the appropriate ambition level here of how how much of an impact we could make but if we can get Fusion to work and if we can make enough of it for the world then if it can like cut the energy cost 10x plus that's pretty great I'll pick that one so your side gig is nuclear fusion I don't I I I'm an investor and sort of like helper of that one it's amazing so so just so I understand you're you're revolutionalizing artificial intelligence and energy not you specifically I think these are I think those are the two my basic model of the world uh is that the cost of intelligence and the cost of energy are kind of what compound and everything else and if we want a radically better future those are the two things we should focus on trying to like make abundant it's incredible so my last question for you is what is the most exciting thing that you are seeing globally in your own company like what is the thing that outside of everything we are all talking about and seeing that excites you about where open AI or even not just AI in general what's the most exciting thing ahead I mean I I think it's this generation of of new scientific progress if these systems can really contribute additional understanding of the world to better technology better science that that is like the sustainable way that the world actually gets better and that the quality of life increases we're not there yet it might be soon it might take a while but I believe we are going to get there and that will I think we all underestimate that it's amazing Sam thank you so much thank you to be clear Sam asked me to talk less and to open it up for you all to ask more so uh first I just want to say thank you and everyone please give them a real Round of Applause for coming here and being so open um so with that I'm going to hand it over to samidar one of our technology reporters and leads to uh lead maybe an open q a ask her own questions as well and uh and and by all means open it up for everybody here to you know take advantage of what we've got here and ask more please come come accepted okay so um Sam wanted uh okay do I have a seat great so uh sandini from open AI if you can join us [Applause] hi [Applause] um sandini is from the policy team of openai um thanks Sam I have I hope you have the bandwidth to take more questions for sure um so I just want to start um I want to refer to this one interview we did with you when you were in YC and you specifically called the big Tech is uh being hyper caps that that was something that you came up during the interview a lot of people think open AI is as powerful or more than big Tech today I I don't think anyone really that's nice of you to say I don't know I'll just come to the question all right um and that's that's because when you propose to um regulate the industry that's also because you want to be part of uh writing that regulation which makes it look like that you know the smaller startups and the companies which are sort of still burgeoning may not have a chance to ever become as big so to be very clear we we've explicitly said there should be no regulation on smaller companies on the current open source models that it's important to let that flourish the only regulation we've called for is on people ourselves or bigger which include Google yeah I'd be us in Google right now I think okay but really just us I think like we're clearly in the lead if it only we're focused on us right now that'd be fine um you know it's I totally get why people are skeptical of hearing someone running one of the companies in the industry call for regulation but the governments haven't been and we think this is important so we have a moral duty to do it and it's totally reasonable to ask that question but we feel strongly about doing it has there been any progress at all from yeah a lot actually it's been a quite a good response um we've met with heads of state in many many countries on this trip and I have been really pleasantly surprised every single time about the Nuance of not slowing down balancing not slowing down uh Innovation all the positive economic benefits everything else and realizing that if this keeps going it can get somewhere that does require Global action do anything to add do you want to add to that um uh I think the only thing that I'll add in terms of Regulation and I think something that we've called for is really setting standards and in a way guiding companies as to what we should be building um because we know these technologies will impact the world and it needs to be a two-way conversation so it really has been about kick-starting that conversation um to kind of have it be a two-way street so we're not deciding for the entire world how these Technologies impact everyone on Sam is because uh usually if you've and you've seen it for the past 15 years uh regulation always follows you know technology this is the first instance where you are proposing to regulate before it's sort of uh it is big but you know I mean the percentage of people who've used chat GPT or any of the llm models will be very small right now um does that dissuade smaller companies and I I think we'll open it up uh if you have an answer to that then to the audience yeah again we are explicitly saying there should not be regulation for smaller companies I think that's important like we're that there's got there's got to be enough Nuance in the conversation where it can't just be like either you're a CEO that says regulation is bad and then you know you are responsible for your industry and bad or you say regulation is good and then you're like trying to like do regulatory capture if that's it like then kind of what what do we want I think what we need is companies to say what they actually believe in not decided that's that's certainly up to the governments but to be able to give input in our case we think for very powerful models models that are much more powerful than what we have today we do need Global regulatory something um and if the world decides that's not what they want that's fine but there's nothing we've said and in fact we've explicitly said the opposite about anything on smaller companies um do you wanna there are no questions great just in case um let's do it yeah these are uh some of the people who had uh sent in questions so if we have the mic um yeah um gaurav uh an academy and maybe you can just introduce yourselves as well so uh hi this is gaurav from an academy five years ago you wrote a blog post which said that the next opportunity that you should pick should make everything else you have done look like footnote now you talk about spoke about Fusion today Etc and there are some clear big opportunities but let's say first entrepreneurs starting out or starting their next company or something like that and apart from the market cap or the potential or the USP what are some traits that do you think on day one say that this opportunity can be super big and can make everything else that you have done look like a footnote I mean I I think this is the most exciting time to start a company since the dawn of the internet I think this is going to be bigger than mobile it might turn out to be bigger than the internet I hope it does but it's at least that big and that means that anything you do uh like can be huge it's been I think hard to figure out what to work on you know these last 10 years because there has not been a big new technology Trend that's gonna like shake the ground and now we have one so I mean I would definitely do something in AI but what to do I'd pick what you like what you believe in make sure that the business idea has like some basic defensibility to it but like it's open season and this is a tremendously exciting time I want to add to that just put on your investor hat is there too much of frenzy around AI you're always critical of uh yeah there is too much of a frenzy Iran AI in the short term so it's it's wildly overhyped in the short term you know people saying like there's crazy stuff happening in Silicon Valley right now but I think it's still probably under hyped in the long term if we if we really do we might be wrong we might hit a wall anytime but if we really do make the progress that we think we're gonna make and we have this like magical system that can just do anything you ask no one knows how to think about that no one knows how to value that but whatever they're thinking is too low so it's yeah short-term underhyped long-term it's a short-term overhype long-term underhyped what do you think um I think I definitely agree with that I think one thing that I'd also add with AI something that's really special now is the way it can reach millions of people across the world like something we've seen in India is there's so much demand for things like education and there's just not enough people who can often active teachers actors doctors actors Loyals with things like AI although that will slowly become more and more possible so that's a very exciting future and the potential is just very large there yeah to add something to that I think we you know we were talking earlier about oh what what's going to happen to the jobs but maybe the problem is like we don't we don't have nearly enough people to do all of the jobs that we want we're we're in this like massive Crunch and if you can make way more like job doing ability available the world would consume a hundred times thousand times more I think we may really see that um more questions um any questions Mohit can we have the mic Sam Rajan here from Peak 15 partners um yesterday was Sequoia capital big 15. I got some questions for you yeah I know I know I don't you're on the hot seat today not me um Sam can you are just going to going to startups I mean as you know we've got a very vibrant startup ecosystem in India um specifically focused on AI are there spaces where you see let's say a startup from India building you know you can build on the models you know be it uh chat GPT and many others but if you want to build foundational models how should we think about that where is it that a team from India you know three super smart Engineers with you know not 100 million but let's say 10 million could actually build something truly substantial look the way this works is we're going to tell you it's totally hopeless to compete with us on training Foundation models you shouldn't try and it's your job to like try anyway and I believe both of those things I think it I think it is pretty hopeless but uh my name is Ajay Chaudhary and I founded HCL the question I want to ask is Ray goodswill and others have been talking about uh you know achieving singularity in let's say year 2045 with the kind of uh exponential growth that your products are going to do is it going to be a much earlier than 20 or 45 and what's your estimate something you want to go first um I can take that question uh maybe for Sam so I'd say timelines that's something we discuss a lot at open AI um different people tend to have different timelines for like when they think that'll happen um I think the thing that you're mentioning around like Singularity though um and some of these sort of more existential risks and like existential opportunities even perhaps um where I think right now where we are and where we really need to think about is like how do we really measure it how do we really evaluate it so we're in a place where we don't even have that right now so I think that's the starting point when we can maybe start to get some more structure around these abstract ideas um but in terms of timelines people can have their own sort of estimates and that can really vary a lot I think we're getting close enough that the definition of the term really matters a lot and people do have very different definitions what I what I would say is we need to plan for a world in which 10 years from now we have something that is like a very meaningful contribution to all of the cognitive ability of human civilization maybe as much maybe more maybe less but an important fraction and you know Singularity or not that is a very different world Kunal my oh honey sorry go ahead yeah soon I'm a creative professional uh I was just thinking while you were talking and I think a lot of new thoughts coming to my head one of the questions I have is that you know there is a something called creative satisfaction to the individual with the creation the tactile sense of it and if the distance and degree of separation starts increasing and the tool becomes so overpowering that it takes away the belonging to the product it can happen to any job actually that the ones who is doing the job sees himself or herself very distance from it completely and it almost the creation creates it's creating itself so what happens to this individual satisfaction which is related to jobs or creation or any of these things would it become self-sufficient in its in its own way and then the two lower Powers you I think what happens when you give people better tools is they do better things they do more impressive things um the floor lifts up the expectations lift up and if I feel very lucky and like very grateful to all of humanity all of Humanity's come before me everyone's built the things that I use but I would not be able to do what I do and neither would anybody else in this room without a gigantic Tech Tree of technology and better and better tools um but you know without the transistor without the operating system that people figure out how to do without all of the work that that enabled for the next step um without airplanes that let me come here and talk to you none of this would happen and so we build better and better tools that abstract more and more but we still find quite a lot of fulfillment and we operate at higher and higher levels and I think that's just going to keep going I think human creativity the desire for status fulfillment from work wanting to like contribute useful things back to the world so other people someday get to build on our stuff like that's not going anywhere the the sort of expectations are just going to go up I think Sam uh two-part questions you can choose to answer one or both uh what have you after doing AI for so long what have you learned about humans uh and what do you think uh uh is your understanding of humans after doing Ai and and if you could be in trenches and be built for more companies what would these companies look like what have you learned about humans so I can think about it for longer um sorry oh yeah uh no I can go first um man so so one is I grew up implicitly thinking that intelligence was this like really special human thing and kind of somewhat magical and I now think that it's sort of a fundamental property of matter and that's that's definitely a change to my world view I think kind of like the history of scientific discovery is that humans are less and less at the center um you know we used to think that like sun rotated around us and then maybe at least we were if not that we were like going to be the center of the Galaxy and there wasn't this big universe and then Multiverse like really is kind of weird and depressing and if intelligence isn't special like again we're just like further and further away from like main character energy but that's all right that's sort of like a nice thing to realize actually um I I feel like I have learned something deep but I'm having a hard time putting it into into words and but it's like something about it even if like humans aren't special in terms of intelligence we are incredibly important you know we I won't have the Consciousness debate here but like I think there's something strange and very important going on with humans and I really deeply hope we we preserve all of that the second part was like four other companies I would start um I think I would just like pick the verticals that I felt I knew the best and think about how AI could revolutionize them so maybe the meta answer is I should be like thinking about how you use AI to Make a Better Faster AI company that's it right yeah um yeah can we get people from yeah we see I've got many questions I didn't want to take over from the incredibly handsome guy in the room but uh many questions one is I really liked what you said in Abu Dhabi I've been reading about your various speeches around the world that seemed the most important about it being regulated like atomic energy so could you explain that more because that seems extremely important to regulate Harare has been making negative remarks or cautions about AI mainly what I've understood he says think of AI in the worst politician that you have in mind you obviously meant without naming the typical warring dictators the next question is are you able to share what you had a conversation with the prime minister and coming to human aspects I had the great opportunity of also meeting coursewell at Google and the most incredible thing he said and it stayed with me please explain that I met him eight years ago and even then he said we are able through AI to make classical music equal or better than the greatest Masters the frontier will be when we make AI or robots capable of love he was very serious about this and I haven't read much about this as if it was his own personal passion has this aspect of humanity which I hope competes with intelligence as an aspect of man progressed that AI will make something like a robot capable of Greater Love than man and dog man and wife father and son is that progressing so on the iaea yeah basically we think and we're not sure if this is the best answer we're kind of contributing one idea of many good ones to the global conversation um in the same way that we say you know nuclear materials provide some real danger some real benefits uh but they affect all of us they affect the globe let's have a system in place so that we can uh audit people who are doing it we can license it we can have safety tests you have to pass as you're doing training these systems before you deploy them there's uh there's visibility for Regulators I think that's an important idea we have been very pleasantly surprised by how much enthusiasm there is for it from around the world and you know maybe someone has a better idea which would be great I had dinner with Harari a couple of nights ago we talked we talked about this in Tel Aviv uh I do think there's a lot of like very sci-fi concerns that are pretty far out there and probably will turn out to be quite wrong but this idea of misuse by a dictator using it to oppress people is a very scary thing and that's not super far away so I think we need to and we spent a lot of time at openly thinking about us I think we need to build these systems in a way to address that risk and I think it's going to be a very complicated Global geopolitical challenge the Prime Minister we're going to see tomorrow schedules got shifted around but really looking forward to doing that and love I hope that we don't all fall in love with robots that would be a deeply depressing um what I hope happens is we are all the best versions of ourselves we all can like figure out how to be better these systems can like help us as coaches as maybe like therapists in the future as as sort of like guides and assistance and make us more present for each other and treat each other better and I really believe that can happen but they'll like all fall in love with the robot thing I'm okay with the good classical music I don't really want that future personally what do you think um I think on that I'd also say it fundament fundamentally gets to some questions about like what you believe AI can and can do I think it's still a debate whether AI models can feel emotions either now or ever um so definitely not settled um will again play into how we even measure things like that so definitely a ongoing conversation right now um yeah Alessandro yep Sam Alessandro from SDA bukuni School of Management the Asia Center education so you talked about education and indeed it has already is helping a lot but I'm looking at it from the other side uh you said it will generate a lot of new jobs we will all be more productive and gather different jobs under ourselves so what do you think are the skills that we should be teaching for the future for the future future managers to nicely manage this gai in order like right now we are teaching about leadership about strategy would it be something like psychology design thinking or a mix of everything something he probably has a better answer on this one than me I'll just add to that there has been a lot of concern raised about chat GPD becoming like a like for a lot of people and while it is fine at a very basic level there have been questions about and concerns about yeah I think one thing that I'll add to that and then I'll take that question as well is we actually also in the Democratic call for AI inputs have asked that as a question like should AI models offer emotional support or like psychological help to humans I think that's an open space and Society needs to decide what role AI will play um but I think to that question I think many of the skills you mentioned um why they're unique is because I think they play into this fundamental aspect of like people skills EQ and like long-term planning and long-term strategy um these are three things that I'd say right now ai models unclear where the growth isn't unclear how and when they're going to get there um so those three things I think are like perhaps the key things to focus on right right now um these aspects which feel fundamentally human because they rely on these things around EQ human connection sort of understanding people um so those areas might be some good areas to focus on yeah just just one question to Sam uh I think in April sometime you had said that open AI would start training um gpd5 but you stalled it because of concerns raised by Elon Musk and others no and it's been a few months so uh no I didn't say we were going to start training gpt5 and I didn't say anything in response to Elon uh it was We There was a letter that some people signed we didn't people asked us are you currently training gpt5 and we said no we're not current again for my earlier statement we just kind of say what we're doing we're we're not training it so we said we weren't that's all but it was not like we were started and then that letter came out and we stopped but is it happening anytime soon training of we have a lot of work to do before ready to go start that model like these things take a long time you can see how long it took us between gpd3 and gpt4 this is like it's not like you just like push a button and say okay today we launched gpt5 uh it you know takes hundreds of people and a lot of research that happens on somewhat unpredictable timelines so uh we're working on the new ideas that we think we need for it but we're not we're certainly not close to ready to start and what you stand on Elon and a bunch of others writing letters wanting to stop any sort of progress to be made on AI um I think a better framework is external audits red teaming safety tests when we finish gpt4 it took us more than six months until we were ready to release it we did your team did a lot of work on it so did many other teams to get ready to be confident that we could put something out that was safe but six months would not have been a magic number and we weren't going to put it out until we were ready and this was a lot of internal work external work future systems may take longer they may take less Long what I think matters is a set of safety standards and a process to ensure compliance with those because otherwise like you stopped for six months and then you you know how do you know if you made enough safety progress but you're not committing to a d ude what to a date for the next yeah I wish I could tell you uh like it's research doesn't like work on a calendar [Applause] no questions okay I think yeah okay I'm Raju kanoria I'm a businessman uh my question to you is that how do you make ethical choices when it comes to using AI and one example is obviously in case you are involved in an accident in a self-driving car or in a situation which can cause an accident or for that matter what you mentioned about medical science that you know in the use of medical science uh you can come up with different ideas on how to deal with a disease but when it comes to ethical choices how how do you think AI will play out in the future you want to go first you want me to go first all right um I think the main thing that I would say we could talk about any of those specific examples but the main thing I would say is those aren't open ai's decisions to make we really want to figure out a way that we engage with society and that we democratize the decision making on these trade-offs so uh the the the projects we've launched recently the funding that we've provided it's it's to figure out a way to get the global value system in the pre the moral preferences of people to decide what these systems do we could go off and make those and it's like very interesting to think about them and we have our own opinions but it shouldn't be like up to open AI to decide and one of the things that I think is so cool about this technology that's different from anything that's come before is this is a technology that can actually learn the collective preferences of the world for decisions like that should we take a few more questions then no um I have the mic here should I go yeah yeah swapping yeah hi I'm swathi I'm the co-founder of cash Guru we are the Performance Marketing space firstly thank you so much Sam for sharing everything so generously and being so transparent about everything uh I would personally love to know a little bit more about the company culture you've built as an entrepreneur at open IAI because it's not just you who's inspired it's your entire team that is building creating something that doesn't exist today so how did you inspire others as well in your team uh you should take that one that's hard for me yeah um I think I can answer um something about the company culture um what you're seeing right now here on the transparency around sort of setting this vision and being very open at the company um that's something we actually have at open AI um something that's really good about the company is how all teams can come together and really work together on Big Ideas together um that requires collaboration that requires sharing ideas that requires not being territorial about work um and kind of collaborating in this manner I think that's what the company is really good at and that's something that I think fam and like others have sort of set from the get-go um I think something else that's really good about the company is like no idea is a bad idea so like no matter how crazy your idea might be or like how sort of far out or how sort of like ridiculous it may sound in the beginning people always hear you out people always engage um so the sort of appetite for always having a discussion is also something that's really good about the company the two other things I was thinking about we we really care about Talent density so I think a lot of companies have talented people but if you have like even a few mediocre people mixed in through there they kind of like act like the neutron absorbers and stuff just goes wrong so we really try to have like extreme Talent density and the trade-off of that is we don't have that many people relative to what we do and so we really try to be focused like gpt4 was a whole company effort we could not have gone and done three other things at the same time um yeah somewhere there sure okay abroad I work for government of India I'm secretary to government of India and we like assistance so I asked jrgbt at 5 PM that I'm meeting Sam what should I ask him and you know the responses that I got were so easy so I think the hypothesis that it is biased is totally confirmed but jokes apart uh there are concerns about energy consumption in large language models and just like the crypto thing do you think for quick adoption in public spaces like the Indian government the lightweight AI is that the way forward of course there is the issues on accuracy and uh so what are your views on lightweight Ai and since you also talked about nuclear fusion I think the energy consumption is at the back of your mind for llms yeah I think look I think this energy conversation about llms has become like a real Sideshow these current models are just not consuming a material amount of energy compared to any like anything else I I don't understand why it's become such a topic of debate I think it is important in the long term if we really keep scaling these models up they will start to consume lots of energy but will need to be on Fusion or Renewables or something like that anyway by that point um just to get enough energy so I don't know how this has become such a meme but I I don't think it is a material Factor I I think you can certainly use small models for some tasks but on on the whole I think you kind of want to use the best intelligence you can unless there's a good reason not to uh and you know like we always want to make AI way cheaper and way more available and way smarter and fusion will certainly help us do that um so that's that's I think why we're excited about it we have another 10 minutes um from Excel okay okay sorry to come in again it's a conversation so I took the liberty on you said about AI not wanting to be human or not competing with human perhaps that's the hint I got not to take over but just like AI will take over jobs because they do it AI will do it better than say the truck driver so similarly when you say human the first thing we know about humans is it's it's human to make mistakes it's it's a human being makes he us to air is human so all we have to do is to make AI human all the qualities of a conversation but it does not air so we have always told our beloved you know mother wife daughter I love you but you know just this one aspect of you it really Riles me it's difficult to believe that everybody in the room hasn't said that to a beloved so this AI robot will displace your most beloved person by having a much better conversation with you without error and what you find irksum about the lover you can program it to not make that mistake and therefore you'll get the perfect lover do you want that yeah it's in in technology I'm a neophyte I haven't been the first mover I'm a late follower so that's how it'll go [Music] look uh first of all I think this question of whether AI is a tool or a creature is something that really confuses people and it confused me for a while too but I now think we are are very much building a tool and not a creature and I'm very happy about that and I think we should and will continue in that direction on the question of mistakes and errors uh I believe that creativity um and certainly the creation of new knowledge is very difficult slash maybe impossible without the ability to make errors and come up with bad ideas and so if you made a system that was certain to never tell you to never say something that it wasn't absolutely sure was a fact um I think you would lose some creativity in that process and I think one of the reasons that people don't like Chachi BT is because it hallucinates and makes stuff up but one of the reasons they do like it is because it can be creative and what we want is a system that can be creative when you want which means you know sometimes being wrong or saying something you're not sure about or experiment with a new idea and then when you want accuracy you get accuracy so I think there's something there uh yeah you know if people want like a and some people clearly do if people want to chat with the like perfect companionship bot that never upsets you and doesn't do that one thing that irks you you can have that and I think it'll be deeply unfulfilling and a sort of hard thing to feel loved for I think there's like something about watching someone screw up and grow and you know like Express their imperfections that that's the very deep part of love is I understand it um and I think like humans care about other humans in a very Inhumans care about other humans do uh in a very deep way um so that you know that like perfect lover chatbot doesn't sound so compelling to me you want to add anything all right yeah Sam yeah Hi Sam okay uh I just wanted someone at the back because they tend to get ignored all right uh Sam hi this is a bit louder oh this is Manish Manish I'm the CTO of TCW we're an asset manager in La so my question is um we're fully expecting uh chat upd to to have a Monumental impact in the the composition of organizations so as we start planning for the future as we start working towards the target State organization and you can use technology as an example how best do we um how best do we create a Target State organization so we have a soft Landing so we have one a soft Landing oh [Music] um I think just like a rapid adoption of the tools in a tight feedback loop for what what to do with them it's it's too hard to predict the future we say it's not open eye all the time it's too hard to predict the future a tight feedback loop is how we manage through it and we just try something we observe we correct and do that again and again and again and I think the world is going to reward um adaptability and speed and resilience like more than ever before because the rate of change will be so fast so I'm great to hear your views about AI I'm curious to hear your views about energy as well so per what the models suggest the energy consumption and Reliance on fossil Fields as of 20 years ago and today is largely the same and we have this great revolution in AI which will you know hopefully revolutionize a lot of things but I'm curious to hear your views on helion and your view on what the next chat GPT for code and code energy would be I don't know quite with Chachi BT for energy means but uh I think if we get Fusion to work and number one we can have the cost of it be like less than one tenth of current energy and number two we can manufacture enough generators for like the whole planet in 10 years then we're in that's great now what of course if you drop the price that much the demand will go up I don't know how much but a lot so we'll have to make even more but we'll figure that out as we go and if we can just start with replacing all base load that's pretty good yeah just um I'm curious what is your biggest fear um if you've you yourself said it could either go completely big or go wrong uh what is your biggest fear about AI I would like to hear something his answer um so honestly my biggest answer right now and I'll share in the five-year tank span um it is the economic displacement question and I know My Views here might differ from like many people at the company um I think the economic displacement question um for example with the Industrial Revolution when that happened long term it was great for the world great for society a lot of progress but they meet you at 50 years after the aftermath were really painful so I think that's what we need to figure out how do we manage this transition how do we make it least painful for society um I think in order to do that there's a lot of work that like governments people have cut out for themselves so I think that's what I'd say in the now is one of my biggest fears in worries I have a lot um I I guess the thing that I lose the most sleepover is that we already have done something really bad I don't think we have but the hypothetical that we by launching Chachi Pati into the world shot the industry out of a railgun and we now don't get to have much impact anymore and there's gonna be an acceleration towards making these systems which again I think will be used for tremendous good and and I think we're going to address all the problems but maybe there's something in there that was really hard and complicated in a way we didn't understand and you know we've now already kicked us off um yeah uh srivatsa Krishna from the Indian administrative service great to see you again Sam uh the question I have I think the smartest move you've done is to go to the regulators and say regulate us that's like saying ask the sun to stop shining because you're way ahead and the audit you talk about of every node of every server of every network will require so much of energy it's impossible for any regulator in the world to do Point number one point number two you often cite the IAA most of the UN bodies are past their expiry date if the U.N had worked Russia would have never invaded uh Ukraine IAA many regard is not a success but actually a failure because Collective action among nations is very very hard to bring about so how did you think of this very smart move to get ahead of government because government always almost always regulates the lowest common denominator it is not designed to do Nuance thank you that's a very cynical take and I really hope you're wrong um and and surely the smartest thing we've done is like create magical intelligence in a computer like rather than like go to Congress and ask for regulation I think they're like I hope incomparable in terms of the impact or the the impressiveness of them but I I totally disagree I think the world can come together on important things I think the UN is in bad shape for sure I think iea is deeply imperfect let's go do something better but those are the best analogies we have um and to say like oh the governments are just hopeless so call for regulation is some sort of 40 chess move it's just like not how we think uh it's this is an existential risk there's many ways to solve it if the governments don't get their act together we will try our hardest to get the companies to cooperate but we can't control what every company does and we'd at least like to ask for like the dream world and if we can't have that we'll get the companies that want to play ball together and do our best hi we can take maybe a couple of more hi Sam you know I heard Elon Musk talk about the origin of open Ai and his role in it and the argument he was making when he was talking about Microsoft's investment in open AI seemed to give the impression that he had an economic claim upon open AI of some sort although he was heading towards that is that completely off the charts yeah I don't really want to get into like an Elon food fight I like the dude I think he's like totally wrong about this stuff you can sort of say whatever he wants but uh I'm like proud of what we're doing and I think we're going to make a positive contribution to the world and I'll try to stay above all of that hi my name is srikanta AI firm called fractal I read your um the paper called Sparks of AGI which was written by the Microsoft researchers in March which is very interesting and it already shows gpd4 already shows several clues that it is it's close to AGI so my question to you is what are some of the tests that you have internally to know that you're getting really close are there any tests and can you share how you would test for that yes and you already talked about the definitions and how AJR their several definitions but what is the definition that you're working with and what are some of the tests that you have to test that it is close yeah great question I think this this is one of the most important like rarely asked questions about what what are the right evals for what an AGI would be um first of all that was not our paper and I don't think we're particularly close I don't think gbt4 is particularly close for me the fundamental thing that gpt4 can't do at all that an AGI could do is go figure something out go discover new knowledge go learn how to solve a new problem it's never seen before figure out that it needs to go do complicated planning study some things in a particular order build something write some test code and the tests that I'm interested in the evals are all around that ability there's plenty of other things you probably have different answers but that's the one that for me would be like all right this is an AGI yeah I think the only thing I'll add to that is we've actually published pretty much every eval we ran on gpd4 so they're there in the gpd4 technical report and the system card some of the tests that Sam mentioned are currently more qualitative so they're done by individual researchers running experiments on gpd4 there's one under the arc section that we've published so should be possible to read about it as well please hey hey Sam nitin Sharma antler uh I want to I have a question about AI with respect to web3 you're also involved with World coin a while back people were saying that AI is a force for centralization and web3 will take it the other way as someone involved on both sides I'd love to get your take I think AI will be a force for decentralization in a very powerful way I think whenever you can give people pretty Democratic access to very powerful tools you it is a force for decentralization and we're seeing this already with the API with Chachi BT so I also had a sort of like fear that air was going to be a big Force for centralization I think without even like being explicit about this my model was that like there was going to be one super intelligence in the sky that like you know we better hope was good and liked us and now what I think is it's much more like we all have like a bunch of systems that help us be more productive and you know you use AI for one thing I use it for another you and I are both like way more capable than we were in the old world but sort of still like doing our thing and amplifying our own will Just One Last Question yeah uh hey I'm Cavalier from zepto We're actually OIC uh and YC continuity company so thank you for all of the work you've done before opening as well um you had a conversation recently with Patrick ollison and uh within that the two of you discussed the problem of not enough Founders working on high-risk High reward very Capital intensive and over a long period you know those types of companies and those types of problems you talk briefly about giving a grant to 100 the smartest people someday I just need to get around to it I I think this is a really good idea any other ideas in terms of how to solve for that um I mean I think there's like a lot of things one could do uh and I think maybe the most important is just like keep like I want to keep trying to deliver the message I'm grateful of other people trying to deliver the message just talking about the importance of this and the feasibility of it and that you actually can raise money and you can get people to work on it and like sure they're gonna like you know it's a little bit harder to get started and people like it takes a long time and people are getting patient but like it's the most fun thing to work on and I think if we just can kind as a society like keep reinforcing that message that it is hard but possible and maybe less hard than an easy startup um I think that's that's the way to do it so uh we're gonna have to wrap this up but Sam are you going to be around yeah so Sam's here if you guys have more questions um you can come up to him he's around for a bit yeah thank you all thank you thank you very much" \
           "JORGE CUETO: Hi, everyone. Welcome to our Talks at Google event. I'm going to go through some logistics first. This is a fire side chat style talk. So it will take about 40 minutes to talk through some questions. And then in the last 20 minutes, we'll open up to the audience to submit questions, both in person here through a mic in the back of the room and also through the Dory at go/ask-sam. And I'd like to thank everyone who has helped out to make this talk possible, including our facilities team and everyone on the PM speaker series organizing team. So it's great to have Sam Altman here with us today for Talks at Google. Sam is the President of Y Combinator, which is widely regarded as one of the top startup incubators in Silicon Valley. He went to Stanford and studied computer science and was the founder and CEO of a mobile location-based startup called Loopt, which was funded by YC as part of its first class of startups in 2005 and acquired by a financial services company Green Dot in 2012. In 2014, he was named president of Y Combinator. And since then, he's worked on a wide range of initiatives from YC Research, which is a non-profit branch of Y Combinator that focuses on doing pure research around moon-shot ideas, like universal basic income. And he's also worked on OpenAI, which is a non-profit AI research company looking into finding ways to create safe, friendly artificial intelligence that can actually help all of humanity. And it's great to have you here. SAM ALTMAN: Thanks for having me. JORGE CUETO: So just as I mentioned, you're involved in a wide range of things from YC to OpenAI. And most recently, you released The United Slate So I wanted to ask you how you think about prioritizing the projects that you work on. SAM ALTMAN: You know, I think optimal time allocation is probably like an AI complete problem. I think if you can get to spending like 1% of your time perfectly, that's really good. And so I think this idea of figuring out what to focus on and what not to focus on is both really hard and still significantly under-invested in. The frameworks that I have used, the sort of two big frameworks that I've used to figure out how to allocate time, one is impact maximization slash regret minimisation. So I try to look at those two curves together. And I try to think about where I can have the biggest net impact on the world, net positive impact on the world. Easy to have a big impact. And then, also, just regret minimization. You know, you get to live once. It's really important that you do what you want to do and that you spend time with the people you'd like to work with and work on the things that you find personally fulfilling. And so if I think I'm going to really regret doing something or regret not doing something, even if I think it's not the best use of my time for a pure sort of net impact on the world, I'm still willing to take that really seriously. And I think that makes me do better at the things I do that do help the world. So you know, the broad things that I've learned that I like to do-- one is teach people. Another is create economic growth. I really do believe that one of the things that is most fundamentally going wrong right now in the country is that we don't have enough economic growth. And the little that we do is not evenly distributed at all. And so I think in a democracy you really want everyone's lives to get better every year. We're basically insensitive to the absolute quality of our lives and extremely sensitive to relative differences year over year to our neighbors. And it's really important that everyone's life is getting better constantly. And I think economic growth is important in that. I think that AI is going to be the most important technological trend of our lifetime. So I spend a lot of my time on that. And you know, I try to think about things on those two strategies. The other framework besides the sort of impact maximization, regret minimization that I found really useful is spend a little bit of effort trying a lot of things, and then relentlessly prune down and focus quickly on the ones that you like and the ones that seem to be working. So in some sense, this is the Y Combinator model of fund a lot of startups with a little bit of money. And then, you know, most don't work out, and some work really well. You spend more time and more money on the ones that do. Hey, guys. This is the thing that I've tried to apply to my life more generally is this idea that I can try a lot of things with a little bit of effort. It's very hard to predict exactly what's going to work and what hasn't. But then the hard part about that, the thing that most people don't do, is you really want to relentlessly focus down on the ones that do work. And the last thing I'll say about prioritization is the other hack I have learned is if you can get one really great partner with you on every project, that will cover up a lot of the slack. Because if you try to do multiple things at once, crises come at the same times. And that's really hard if you have to do it all yourself. JORGE CUETO: And focusing more specifically on productivity, what are some life hacks maybe you apply to make your everyday more productive? SAM ALTMAN: I mean, I think there's like a lot of crap written about productivity, secrets on the internet. And people sort of like get into this thing where they spend more time trying to be productive about their productivity system than actually getting things done. Well, say two, I think, pieces of advice that aren't that obvious. One is, I think, far more important than any particular system is just figuring out the right things to work on. And so all of the time that people spend with this new productivity app or that or whatever would be better spent like really trying to think diligently about I have the same number of hours as anybody else. What am I going to spend them on? And getting that right is more important than exactly like being perfectly productive with those hours. A big part of that is not doing things that waste time. I think if you can just focus on the things that are important and not do the things that waste time, you can be fairly sloppy with productivity otherwise, and you'll still get far more done than most people. It's really hard to do, though. The other thing that I think people don't think about enough is figuring out your own personal rhythms of productivity. And there's huge variance, I've noticed, between people that figured this out and don't. So for me personally, it turns out that I am most productive if I go to sleep late, wake up late, and then keep the first like three or four hours of the day and don't schedule any meetings, like work from home, get there my list of stuff then, and then pack all my meetings when I'm kind of less productive at just grinding stuff out or thinking creatively in the afternoon. And it took me some number of years to figure out, because it didn't fit well with the work schedule I was naturally in. But then I was like, all right. If this is the thing that makes me most productive, then I'm going to make my whole schedule work to support that. And that was a really important change for me. So I think figuring out your own personal optimal times to work on what kind of different things, people don't really talk about that much. And at least for me, it had a huge impact. JORGE CUETO: Shifting gears a little bit, but still trying to get your perspective on different things related to day to day, but one of the key issues that has come up recently is bias in the workplace. and both conscious and unconscious bias. And I wanted to get your perspective on what are some of the strategies that you implement personally, whether in the way you interact with people that you encounter or in how you approach the decision making process and using strategies to minimize your own bias. SAM ALTMAN: Look, I think this is an important conversation happening in Silicon Valley right now. And there's a lot of opinions on a lot of sides. But I would just like to say the following. I think no matter what you believe about biology, no one that I respect does not believe that women and racial minorities and a number of other groups face an absolutely unfair playing field their entire lives. I think people start getting told directly or indirectly from the very young age this is the kind of thing you should do or can do or whatever. And that has an effect, a [INAUDIBLE] effect on anyone. And I think trying to counter that is really important. And again, I think there are things reasonable well-meaning people can disagree on. I think, unfortunately, we spend all of our time talking about the disagreements. And we don't focus enough on the agreements. And I think almost all smart, reasonable people will agree that the society we grew up in has a hugely unfair playing field. And I think because of that, it is not enough to talk about unconscious bias. I think that is a real problem to be clear. I think we are all a product of the society we grew up in. And we all have biases that aren't our fault, but still have a responsibility to counteract. But one thing I don't like about the discussion in Silicon Valley about unconscious bias and how that's the problem that we need to fix is I think it is not nearly sufficient. A good thing to fix, but it ignores the fact that, you know, decades or centuries of society have built up a very uneven playing field, and that is why we do need programs to try to proactively counter that. So you know, I think it's really important we not lose sight of that. And that unconscious bias training alone, although currently very fashionable, will not fix that. That said, I do believe unconscious bias is a problem. We try to counteract it, A, by talking about it and doing training, which I think does help. But B, I think one of the things that we have done that, unfortunately, other investors have not done as much is just have a very diverse partnership. You know, we have six female GPs on our team. And that's probably a large part of the women in top investing roles in Silicon Valley. And that's really bad. We have the CEO of our corp program is black. And I hate to play the kind of like, who's the most discriminated stack game. But I think black entrepreneurs in Silicon Valley have an exceptionally hard time. And I think by having a more diverse team, it helps us have broader networks and also think about our own unconscious bias all the time. JORGE CUETO: And the issue of politics or maybe even bringing these issues of in the workplace is sometimes seen as a taboo. And yet, you've been pretty vocal about your views on current political events and also other issues that are coming up in Silicon Valley. So I wanted to ask you how you walk that fine line between expressing your opinions, but also minimizing any repercussions that that could have on the day to day business of YC. SAM ALTMAN: Well, now it's not even controversial. You know, like now, all the tech CEOs are talking about politics. When I started doing it a couple of years ago kind of at the beginning of the rise of Trump, it was controversial. Two things were going on. One is I think no one took him seriously. So most people were like, yeah, this is a ridiculous thing that's going to go away. Two is that I think in normal times, it does make sense for business leaders of large organizations to remain apolitical. You know, I think it actually does make a lot of sense. It's a huge distraction. It's hugely time consuming. And it has all of these, like, weird negative effects, like you know, if you piss off the president, he can do bad things to you. However, these are not normal times. And I think when the future of the republic is at risk, the duty to the country and our values transcends the duty to your particular company. and your stock price. And I think I started that a little bit earlier than other people. But at this point, I'm in very good company. And it doesn't seem to be that controversial anymore. JORGE CUETO: What are some things that you wish people knew about you that they don't know about you? SAM ALTMAN: You know, at this point, I would just like to have my own little quiet private life back. I'll say nothing at all. JORGE CUETO: OK. Fair answer. Moving on to talking a little bit about YC and what you look for in companies, are there qualities in founders that you think are overrated or underrated? SAM ALTMAN: Yeah. I think the most underrated quality of all is being really determined. This is more important than being smart. This is more important than having a network. This is more important than a great idea. The hardest thing about starting a company is the level and the frequency of bad stuff that happens to you. And most people that are good in really other ways eventually just get killed, the company gets killed, by stuff going wrong. And you know, so much about being a successful entrepreneur is just not giving up. When we have funded people who have a great idea, perfect background on paper, and a great product and still failed, it has usually been that they're insufficiently determined. So I think this is the most important non-obvious skill of a founder. Of course, you need a good product and a good market and to be smart. But that's really obvious. The degree to which being like a three or four standard deviation outlier on determination is a required skill of a CEO is not something that was obvious to me when I started. That's also bad, because it's really hard to select. It's really hard to identify that. As we have said more publicly how important that is, people applying to YC have gotten better and better at telling us stories from their past life about how they overcame these impossible odds to get through something. And unlike intelligence, which is very difficult to fake in a, you know, one hour meeting, you can definitely fake determination in a one hour meeting. So that's one thing that really matters. Another thing that really matters that is non-obvious is independent thought. And this I think is an even more unusual skill than determination. I think both of these you can make a conscious effort and build up. But I think independent thought is one of the hardest skills to build up. Because speaking of social pressures from birth, we are all pushed to think like other people. And if you think in your own lives about the number of people you spend time with that you would say are true independent thinkers that consistently have new ideas you haven't heard from other people and think about the world in different ways, it's probably a very short list. And yet, these are the people that start all the interesting companies. The consensus idea is everyone tries Google will eat your lunch at. And they're also not kind of the really big trends of the future. You want startup ideas-- if you picture a Venn diagram, and here you have is a good idea, and here you have sounds like a bad idea, you want that tiny little overlap. And those are the kind of ideas that are the hardest to identify and the ones that, even if you do manage to notice them, most people will talk you out of. So I'd say those are two non-obvious skills that we look for. JORGE CUETO: And what's one challenge that YC companies face repeatedly that you notice? SAM ALTMAN: Hiring engineers, when Google can just sort of like throw unlimited cash at anyone they want, has become very problematic for startups. I think the good thing about that-- I always try to find the good in any bad situation. And the good thing about this is it means that all of the really good startups have really important missions. Eventually, they figure it out. They may not have it on day one, but they eventually get to this, like, missionary mindset. And it used to be that even if you didn't have that, you could just sort of get a bunch of mercenaries to come work for you. And now you can't, because you can't [INAUDIBLE] Google. And so one positive side effect of this thing has been that the importance now of a startup having a really clear and really important mission on day three has gone up a lot. And I think that's leading to better startups. Because, otherwise, you just can't recruit. Another common problem that startups have-- and this doesn't sound like a great insight. But most startups still don't ever built a product that people want. And it doesn't seem to matter how much we talk about this. It doesn't seem to matter how much anyone talks about this. People still keep trying to do anything but this. And if there's one thing that a startup has to get right, it's build a product that people really want, not a little. If they want it a little bit, then you won't generate enough momentum. Like, you've got to build something that some people really love. And after failing, because of insufficiently determined founders, this is the number two reason that startups that seem really good otherwise fail. JORGE CUETO: Moving on to talking about different technologies, what would you say is the biggest challenge that we're facing in terms of making progress on artificial intelligence right now? SAM ALTMAN: Well, I don't know if any of you saw this, but OpenAI beat the best single player DotA players in the world last Friday. And when we started that project at the beginning of this year, I did not think that was going to happen this year. And I wasn't even sure it was going to happen next year. And it was very wild to watch that happen. Because it was almost purely self-training. And it was this very complex environment. And the AI was just playing itself and getting better and better and better. In fact, the final bot that we had that beat all the humans handily, one day later, it lost 60-40 to a one-day-more evolved version of itself, just to give you a sense for the rate of improvement. And so I think people are kind of asleep at the wheel here. There are problems. But again, in the same spirit of always trying to figure out the good, not the bad, we are making unbelievable progress, maybe too much progress. But I think of all the things I worry about with AI, the technical barriers to progress are not the top of the list. JORGE CUETO: There's another camp that says that maybe we're placing too much emphasis on the threat of AI. What do you think about that? SAM ALTMAN: Yeah, I think we don't talk enough about the benefits. I think that AI has the potential to eliminate nearly all human suffering in the next couple of decades. I think we can have a world of abundance. We can eliminate poverty over time. We can probably cure a whole lot of diseases. There all these wonderful things that technology can do. I think we're already seeing that in just how much better a lot of consumer products we use everyday have gotten. People like disaster porn. People are more interested in talking about the end of the world than they are about life getting 10% better every year and having that compound, which gets a lot better. So you know, if you're a journalist, you can write an article about how AI is going to end the world and get a lot of clicks and, you know, a page view bonus or whatever you get. Or, you can write an article about how AI is gradually making all these problems 10% better. And probably no one reads it. Certainly, no one shares it. And so I think, for whatever reason, the way we're wired is to talk much more about the downside of this than the upside. But the upside I think is going to be huge. It already is huge. JORGE CUETO: And what do you think about cryptocurrencies? Do you see the same growth? SAM ALTMAN: Yeah. I mean, I think it's going to go up and down. Like I bought my bitcoin a long time ago. I plan to hold them for a really long time. I try not to watch the price ticks, but it's so addicting that I can't help myself. I think-- this is not investment advice. I think the only super compelling proven use case we have seen so far is store value. And as a replacement for gold, I think we are seeing real adoption there and real collective belief that actually makes it have some value. However, if that's how it's going to play out, then I think bitcoin should dominate-- biggest network, first biggest brand, most collective belief, whatever. And so I have been surprised by the continual strength on all of the altcoins. I think there are potential other truly valuable applications of the blockchain. Filecoin is a YC thing, so I know that one pretty well. And I can see that being big. But I think most of what's going on, outside of bitcoin, feels like a complete speculative bubble. And I feel bad that a lot of people are going to get burned. So I think probably the right thing to do, if you believe in it, is to buy bitcoin, and then not think about it for another five years. JORGE CUETO: Is there any specific product area or technology that you think people are sleeping on? SAM ALTMAN: Sure, a lot. AI, as we mentioned, I think people are asleep at the wheel on a really big way on. Nuclear fusion, I think, is within some single digit number of years of working. And because it's been so bad for so long, people are just kind of burned out and not really taking a new look at new materials and stronger magnets and better computer models that's going to enable this to work. Synthetic biology-- again, it's like people talked about it a lot a couple of years ago. It didn't quite work as fast as people were hoping. So we have like this hype cycle, and then it really falls off. And now, we're in the part where I think the interesting work is happening. And people aren't paying enough attention. I guess, that's a topic I can go on for a long time. But I'll limit it to three. JORGE CUETO: Sure. Is there any particular problem that you think technology can't solve? SAM ALTMAN: How to make us nice to each other technology has clearly been quite bad at solving. I won't say it can't. But I haven't seen it yet, and I certainly don't think technology can by itself. And I think we are kind of in the situation, at least in the developed world, where the world keeps getting better, and we keep getting unhappier. And you know, there's like a decent amount of data on this. And I think technology is not entirely to blame, but it's certainly not blameless. And I think 30 minutes left, I couldn't even start the conversation. But I think the number of things that technology has done to make us more isolated, feeling relatively worse-- a friend of mine a little bit older said she never used to be unhappy. Because she had no idea what she was missing. And now that she has to watch, like-- I'm very bad a pop culture, I'm going to pick a name at random-- Kim Kardashian fly around in private jets on Instagram all day, she's jealous. And it makes her very unhappy. And it didn't used to happen. And I've been thinking about that a lot in the last couple of weeks. And I don't have a solution to that. But I understand why that's a problem. So I think figuring out how to make us happier and nicer to each other in particular, I think one thing that technology does that's really bad is we have some probably long-standing evolutionary pressure that even if I really don't like you, I'm very unlikely to come stand next to you and say, I fucking hate you. You're a jerk, you know, whatever else people say on Twitter. JORGE CUETO: A lot of things. SAM ALTMAN: Because we're like these pack animals. And we have to live with each other and help each other survive. But somehow on Twitter, that goes away. And I think I'll save my whole rant about Twitter. But I think that is a platform in particular that rewards saying the most aggressive snarky things. That's how you get likes and re-tweets and sort of value out of the platform. But a lot of technology does this. We don't have whatever kind of the human, being nice to each other in person, instinct is. And we have these platforms that reward being bad, reward being a jerk. And so I think I'm not optimistic that technology is going to solve that problem. I think that's going to have to be people solving that problem. JORGE CUETO: In an interview with in 2015, you mentioned that you were optimistic about the future. And that was right before all of the election stuff happened and the situation that we find ourselves in. So would you say that you're still optimistic about the future? SAM ALTMAN: Yeah, of course, of course. Like, progress, it's not a perfectly exponential curve. It's not even a straight line. And you know, we are clearly in a challenging period now. But I think if you look back at the last few hundred, and then few thousand years, if you zoom out enough, the squiggles on the curve kind of disappear. The world's getting so much better. And I think that's going to keep happening. And even with everything going on right now, I'm delighted to be alive right now and not 100 years ago, and certainly not 200 or 2,000 years ago. And I think we do have technology to thank for a lot. And we have better governance. Like, the number of people living in an democracy, you know, 200 years ago was very low, the percentage. And as horrible as things are, the fact that we get to stand up and speak our minds without fear of being thrown in jail for political opposition and the fact that we get to vote again in 3 and 1/2 more years, I think that's amazing. And I think it's easy to take that for granted. But yeah, I think the future is going to be a lot better. I remain very optimistic. JORGE CUETO: What do you see as being a big challenge that we're facing as a society right now? SAM ALTMAN: How we deal with a world where the natural forces are for wealth to concentrate into the hands of a smaller and smaller number of people. As I mentioned earlier, I think people are more sensitive to relative quality of life than absolute quality of life. And I think technology is naturally a force. It's a giant lever that tends to create way more wealth, but really concentrated. So I think one of the most tone deaf things people say in Silicon Valley is, you know, poor people should be happy. They get this Android phone for not much money. They can access anything in the world. And they wouldn't have that without us, so why are they complaining? And OK, like there is some truth to that. I do think it is cool about the world that the richest person and someone living in an absolute poverty carry around the same phone. There was no analogy to that other than maybe like if you got a really bad disease. There was no like equality like that, you know, 400, 500 years ago. However, that point, which is always what Silicon Valley falls back to, I think is like maybe not the most tone deaf possible response, but up there. Like people want to feel like they have agency. They want to feel like they have a voice in the future. They want to feel like they can participate. And they want to feel like they're not just kind of like given this baseline, while like they toil in the provinces and Silicon Valley just gets all the money. And I think people who don't see that are just not thinking clearly. And so I think one of the greatest threats-- something else I don't think technology can fix on its own-- is how we get to a more just world. I really, really fundamentally believe that economic justice is the most important thing you can do for social justice. And if you have all of the resources going to a small set of people, even if everybody else is having their absolute quality of life raised very quickly, that's not enough. JORGE CUETO: You recently announced The United Slate, which puts forth some policy proposals as well as an invitation for candidates. What would you say success looks like for that? SAM ALTMAN: You know, if we could run five, six candidates in the 2018 cycle on that platform and have two of them win their elections, I think that'd be an incredible start. And you know, maybe it doesn't work at all. Because maybe those issues, although I believe they're important, are not yet ready to convince the public at large. But I think it will be a good start. And I think over time it will be really good if people on the progressive side built up a kind of long-term organization focusing on winning elections and shifting public perception at all levels. The right has done a fabulous job with this. Congratulations to any of you who are on that side. But I would like the left to do a better job at that. I don't think we're putting forward our best game there. JORGE CUETO: In your invitation, you also mentioned that you would be willing to work with Democrats, Independents, and Republicans. Is there any issue in particular that you see anyone, regardless of political ideology, coming together and agreeing on more so than other issues? SAM ALTMAN: I think there are a lot of issues. Again, I think people agree on way more than they disagree on. You know, as we went around the state and talked to Californians, Republicans, Democrats, San Francisco, LA, Fresno, Shasta County, wherever you go, the price of housing is like the biggest issue for most sort of regular people that are not Google employees, maybe even for Google employees. It's really, really bad. I mean, this is if you could fix I think one thing that would have hugely positive secondary effects, it's bring the cost of housing down by a factor of 10. It'd be transformative for society. It's a-- AUDIENCE: [INAUDIBLE] government regulation? SAM ALTMAN: What? AUDIENCE: Eliminate government regulations. SAM ALTMAN: Eliminate government regulations? AUDIENCE: Five stories. SAM ALTMAN: Yeah. Like, I think many regulations have good elements. I'm not kind of the libertarian, anarchist, all government regulations are bad. But I do think that the sort of no more building, no building taller, has been disastrous for the state. And I think it is the worst possible allocation of resources to have people tie up every free penny they can find into the place they live. Think about anything else we could spend that on. Think about what it would be like if people could live close to where they work rather than commuting an hour and a half to get here each day. And that is something that Democrats, Republicans, Independents, almost everybody agrees on, or at least there are people in all of those camps that do. So I think like, again, easy to talk about the divisions. It's really good that when you talk to regular people, they all agree on what the most important issue is. And they all want to fix it in the state. JORGE CUETO: What do you think the tech industries role is in government and politics? SAM ALTMAN: Look, I think we are all citizens of this country. And we all have, like-- you know, there is a right to participate in the electoral process. And I think there's also a duty to do that. And I think tech is going through such a boom right now it is easy to say, hey, I'm just going to focus on, like, doing my thing, building products, making money, and whatever. And I'm going to let someone else take care of the rest. One of the kind of disappointing things that I have learned as I've gotten to spend more and more time with increasingly influential people and kind of how the world works is that there is no plan. And there is no group figuring out everything. And it's kind of up to all of us. Everyone hopes. Like, the reason conspiracy theories are so appealing is that everybody wants there to be a conspiracy. You want to think that someone has a plan, that, you know, there's all this stuff happening. But someone's got a centralized plan, and it's all going to work out. And I think one of the sad realizations of growing up is that there are no grownups. No one has this master plan. And if we don't participate, the thing can just go off the rails. JORGE CUETO: What do you think are some of the most effective ways for employees at a large tech company, like Google, to get involved in government and politics? SAM ALTMAN: Everyone wants an answer other than this one, because it would be more convenient. But I think one of the answers is to just run for office. We have this process. We have this system, set of rules, that we've all agreed to. And everyone wants some way to act around the edges of that rather than just participate directly. And that's OK. There are good things to do. But I think just taking the problem head on, not enough people try that. JORGE CUETO: And there's rumors going around that Mark Zuckerberg is going to run for office, like, every other week. And then there's also been rumors about you running for governor. And we've seen tech people run for office in the past. Meg Whitman ran for governor of California in 2010. But she lost by a significant margin to Jerry Brown. So my question is, do you think that it's actually feasible for someone in tech to run for office and win? Or is there too much of this perception of the tech industry as being elitist, such that people won't connect with voters? SAM ALTMAN: I think there is. I think, at least, people should try. I think the tech industry is the most hated in the Bay Area. And if you go out throughout the rest of the state or the country, there's a lot of people who think it's really cool. They aspire to it. They want to participate in it. And I think it is easy to get too negative a view of how technology people are perceived here. I don't know if a tech person can win the presidency. I have a feeling we're going to find out. But what I am confident about is that people from the technology industry could start winning local school board and city council and, you know, congressional seats. And that would be a great thing to start with. JORGE CUETO: Is there any person currently living that you would want to run for president? Who's your ideal candidate? SAM ALTMAN: Ideal? I can't answer that on the fly. That's a good question to think about. When you said that, I was like, oh, I should figure out who that person is and go try to convince them to run. But I don't have an answer ready to go in my head. JORGE CUETO: OK. Well, with that, I'm going to open up the floor for audience questions. So if you have a question, feel free to go to the mic in the back of the room, or also submit your question to the Dory. AUDIENCE: [INAUDIBLE] Hi. You mentioned the anecdote about your friend being unhappy and Kim Kardashian. And it reminded me of a quote. And it said, people aren't unhappy, because they want to be happy. They're unhappy, because they want to be happier than other people. And you mentioned that technology may or may not be able to solve this. So I'd like to hear some of your ideas or success strategies on how to solve this on a micro and macro level, whether it be delete Twitter to-- SAM ALTMAN: That's a good thing to do. That's a good thing to do. Yeah. I deleted all the social apps from my phone. And yeah, I can still check them on my computer when I want. But I don't have that constant urge to push button for dopamine hit here. And that's been really good. You know, I think after talking to a bunch of these people about the things that make people happy, there's the obvious stuff, which is like spend time with loved ones that everyone knows even if they don't do. But there's a bunch of things that are less obvious to me that seem to have huge measured effects. Like taking time to think about the things that went well as opposed to things you're upset about, or going for a walk outside everyday no matter what. And I think as we get sort of to abundance and unlimited resources, this is going to be a more important topic. What I would encourage you to do is to just like start reading. There's a lot of literature on the subject. No one seems to care about it enough to spend time. But I would say start reading it. And hopefully, I'll finish my blog post on it soon. Thank you. AUDIENCE: Hey, Sam. Thanks for coming. I wanted to ask a question about the larger landscape of VC in general. I heard a rumor that YC is looking to a growth fund. I think it broke on TechCrunch like month ago, like potentially raising $1 billion fund. I wanted to get your thoughts on growth versus venture and how you see growth evolving for the Bay Area in general. You see private companies staying private longer and longer. SAM ALTMAN: So we already have a growth fund. It's called YC Continuity. We raised the first one in 2015. It's about halfway invested. And it basically follows on in capital in YC companies. One of the things that I wanted to do after I joined YC was start to fund hard tech companies, nuclear fusion, something like biology quantum computing, self-driving cars-- long list. And one of the good things that I realized is that nobody else was funding those companies. And so we could have our pick. One of the bad things that I realized is nobody else was funding those companies. And so we could fund them all we wanted, and there was no follow on capital. So that was actually the genesis for our growth fund is that there was this class of companies that I think are really important and really valuable. And they weren't getting funded. Since then, we've expanded it, and we fund lots of other companies. I will certainly say that there is no shortage of growth capital for software companies in Silicon Valley. You know, it may have gotten harder to raise a seed or an A round. It probably has somewhat. But if you have things working, like when you want to go raise a B or C round and you have this beautiful exponential growth, you will not be able to keep up with the number of term sheets you're getting. That is the stage that I think just has a huge amount of capital allocated to it. As companies are staying private longer, as public market investors have a harder and harder time finding alpha, they are more and more willing to do stuff like this. So that part of the market is not suffering, at least, not yet. AUDIENCE: Thanks. SAM ALTMAN: Sure. JORGE CUETO: Let me do a question from the Dory. We have a question about universal basic income and how Google has been supporting GiveDirectly's research on UBI in Africa. And you're a proponent here in the US. So what are your thoughts on how, when, and where the universal basic income approach might be most effective? SAM ALTMAN: Yeah. I don't think universal basic income is the solution to all problems. I think, in fact, of the bigger problem that we were talking about earlier of what makes people happy and fulfilled and feel needed, and valued, and have meaning in their lives, it is not sufficient to solve that problem. And I don't think it will replace the entire other social safety net, like the people who are like eliminate everything else, you know, no health care, no schools, no minimum wage, basic income. I don't believe in that either. But I do think that if we do all of our jobs, if we Silicon Valley do all of our jobs, we will create more wealth than the world's ever seen before and less jobs. And in that world, I think there is a moral obligation to eliminate poverty. I think poverty is a, obviously, very bad thing. But it is worse even than people realize. If you look at the studies on the long-term psychological damage that living in poverty does to people and how it means that you never get a chance to really invest in your own future, because you're always just trying to survive, I think there's just a huge amount of wasted potential. And so you know, there are a lot of arguments about UBI. This was another thing. Like, when we started this couple of years ago, I did not predict at all that this was going to ignite into this big national debate. It was like, we were just trying to hire a researcher. You know, like, maybe this is a good idea. Can we just do a project? And it's just been like-- so I don't think I quite understand why it has become such a national issue so quickly. But I do think that longer term, if we have the ability to eliminate poverty, we will get a lot more out of the world as a whole. JORGE CUETO: As you started the experiment in East Bay, have you noticed anything that maybe you didn't expect, or has it changed your attitude towards it in any way? SAM ALTMAN: You know, we're like seven or eight months into a five year study. So not yet. JORGE CUETO: OK. AUDIENCE: Hi, Sam. I'm thinking more in general of founders, but this could be general, too. But what advice do you frequently give, but you find most people never actually follow through on? SAM ALTMAN: I mean, no one ever listens to any advice of any sort. So, all of it. I think the thing that people-- well, the piece of advice that people later say they wish they had listened to is that it is very easy to get sucked into a path in life. And you can do things like, say, oh, I want to start a startup someday. Or, oh, I want to be an AI researcher someday. But first, I'm going to go do this other job to, you know, make money and gain experience and whatever. And it's so easy to get sucked into a path where you spend your entire life doing something that is not really what you want to do. That's probably the piece of advice that I have given people that they have most often come to me, like, five years later and said, I really wish I had listened to that. AUDIENCE: Thank you. SAM ALTMAN: Sure. AUDIENCE: I'm curious to hear your thoughts on the relative rates of progress in AI between China and everywhere else. So you mentioned nobody has a plan, but China has a plan for state level centralized investment in AI. Whereas, Elon Musk is calling for regulation that would slow down-- SAM ALTMAN: Yeah. AUDIENCE: ----[INAUDIBLE] everywhere else. SAM ALTMAN: China does plan, that's true. It doesn't always work. They don't always have global coordination. You know, like right now we're in this kind of world where it seems like you have the internet in China, and the internet in the rest of the world. Maybe they have a plan for their piece of it. I don't honestly know how far along China is with AI. And I don't think anybody else honestly really does either. I think it would be bad to get into an arms race with China over AI. I think that's something we should try to avoid. And I think there is a real opportunity, although we may not have the leaders in place to do it right now, to make this a joint kind of worldwide project, rather than another space race or nuclear arms race. Thanks. AUDIENCE: Hi, Sam. I was wondering if you could expand a little bit on funding hard tech. Because I think there's a big problem with private capital allocation. And you know, like, $70 billion was put into VC last year, which is a drop in the bucket in terms of worldwide investment. So do you see YC maybe raising an $100 billion fund in the future? SAM ALTMAN: Yeah, maybe. AUDIENCE: Like, yeah, how can we solve this? SAM ALTMAN: I think capital is allocated really badly. And unfortunately, there are huge efforts-- like if you have this really valuable thing which is you get access to invest in great startups and most of the world doesn't, then there will obviously be a super return there. And you're going to work really hard to protect that. And so I think expanding access to invest in startups-- which is happening, but slowly-- is a really good thing to do. And I think, you know, equity crowdfunding we're still in the early days of, but is an important trend. And I think that will change the capital allocation. I think you're seeing startups in all these different ways go to non-traditional funders. And that's been really good. We first saw that with consumer hardware. We're now seeing that in a lot of other places. You know, I think the other thing that's happening, finally, is there's just-- and there's bad to this, too. But there's just a huge amount more capital coming in to fund early stage private companies or mid-stage private companies. And I expect that in a world where interest rates stay even close to as low as they are, we are in the very early innings of that trend. So my general model is that the world's a very complex financial system. Capital sloshes around looking for the best return. There are periods where there's a really outperforming return, but then more capital gets allocated there. And I think we're seeing that now. AUDIENCE: But do you think that a nuclear fusion company could raise $100 million in an ICO or something like that? SAM ALTMAN: Yeah. Or maybe I wouldn't suggest that they do an ICO. But I do think they can raise $100 million. And I don't think they could have three years ago. And I think that's a really positive trend for the world that this stuff is now at least somewhat possible. AUDIENCE: Awesome, thanks. SAM ALTMAN: Sure. JORGE CUETO: Another Dory question-- what are the most common reasons that qualified candidates get rejected from YC? SAM ALTMAN: Well, there is one particular thing that happens a lot with super talented people from large tech companies. So since I'm here, I'll mention that one, which is you are a really great person, really talented, really smart, really driven. And you don't have a good idea, or you don't have any idea. So you make up a bad one. And there's this, like, myth about startups that the idea doesn't matter at all. And I think there's existential proof that that's not true. And I think there is this particular failure mode of people from the big tech companies which is like, hey, I'm really talented. I'm like, yes, you are. So I'm going to start a company. And I'll figure out what to do later. And I think that isn't usually what produces the great companies. And so we have learned that it's much, much better if you're otherwise a qualified candidate to have a good idea. And I think that would be the common failure case for people coming out of Google. AUDIENCE: Hey, Sam. SAM ALTMAN: Hey. AUDIENCE: So what are your thoughts about, you know, where you're going to go or what you're going to do with your life after YC? Or does that come across? Like, are you going to take a political office seriously? SAM ALTMAN: You know, I don't even know what I'm going to do in three weeks. I plan to run YC for a really long time. I do plan to get continually more involved with politics. But I'd like to support others, not run for office myself, at least not any time soon. Like, I am a big believer in do the things that you think about in the shower in the morning when you can think about anything you want and your kind of mind is just off. And the things I keep coming back to are how can I make YC like 100 times bigger? How can I make sure that the arrival of AI goes well? And in the short term, how can I help our political system from going off the rails or any more off the rails than it already has? So you know, I kind of plan to keep working on those things for, hopefully, you know, a really long time. AUDIENCE: Good to hear. Thanks. AUDIENCE: Hi, thank you for being here. I have a question about the general way Silicon Valley works. Because it seems like it's a system in which you have the most talented minds dealing with maybe not the most important issues. Like, you have the sharpest mind working on social apps or mobile apps. But we still don't have a cure for cancer, or we still don't have another way of having energy, or really important stuff that the world should handle. And So my question is, do you agree with that? What is your perspective on that? And how do you think maybe this can be addressed? SAM ALTMAN: I don't agree with that. I think I used to view my job as a capital allocator. And now, I view my job as a talent allocator. So most of my day is spent meeting with really smart people and trying to convince them to work on important problems. And you know, I think in 2007, what everyone said is the best minds of our generation used to build spaceships, and now they're like moving numbers around on Wall Street. And in 2017, what people say is the best minds of our generation used to build spaceships. And now they get me to click on ads. And you know, there's always some truth to that. And there's always someone to pick on there. But I think OpenAI has some of the smartest minds in our world of our generation working on having AI go well. I think Helion, which is that fusion company I mentioned-- some of the smartest minds of our generation working on nuclear fusion. YC, I think, last time I counted funded eight companies working on a cure for cancer, incredibly talented people-- or cures for cancer-- cancers. I think you can always say there's all these people like working on bad stuff or stuff that doesn't matter. But you know, I think Google is still like a really great thing for the world. AUDIENCE: This is why we're here. SAM ALTMAN: Yeah. And I think it does matter. I think it's always easy to pick on people and say, you're not working on a cure for cancer. You know, you're wasting your time. But you're making this thing better that people use every day. And their lives would be a lot worse if it went away. And you're making it better every day. And I think it's really easy to pick on people and say, you know, that person's not spending her time right. And I think it always says more about the person that says that than the person they're pointing to. And if you're doing something useful for the world, if you're doing something you enjoy, even if you're having a small impact, but on a product that a lot of people really use and love, I think that's really valuable. And I think the people who say this generally have a lot of insecurity about how they're spending their time. AUDIENCE: So you don't think like Silicon Valley is avoiding the tough problems? SAM ALTMAN: I invite you to come sit in my office for a day and listen to the people coming through and what they're working on. I really don't think that, no. AUDIENCE: OK. Cool. Thank you. AUDIENCE: Hey, Sam. Seeing that you're a largely influential public figure, could you speak to the privileges that might have led to that and helped you with your success and how you may be good or bad ally? And then also, seeing that a lot of our consumer products are largely bias, specifically to the people who create them, which is largely the Silicon Valley engineers like myself and others in this room, how do you keep your ideas and thoughts diverse in addressing intersectional needs? SAM ALTMAN: Yeah, great question. I basically had like nearly all of the possible privileges. I had wonderful, loving parents. I grew up in a safe house. I'm a white guy. We had enough money that I was able to pursue the things that I was interested in and go to great college. And it's never lost on me how if I had been born a mile in a different place to a different family, different skin color, different gender, I wouldn't be where I am now. I view that as an obligation to try to make the world more just going forward. I think anyone who is really successful and doesn't-- I think anyone should try to do the best they can with whatever hand they're dealt. But if you're dealt, you know, like four aces, and you win, then I think you have an extra obligation to try to sort of make the world a little better. So I try to be really thankful of what everyone's done that has allowed me to do this. I also try to figure out how to pay that forward. And I think anyone who is really successful or almost anyone who is really successful has like privilege, luck, skill, and hard work. And I think people who try to say it's just one or just the other all tend to be wrong. So I'm thankful for that. And I try to pay that forward. In terms of biases in the product, I think this is one of the reasons that diverse teams are most important, the moral question aside. The consumer products, the teams, the companies that I think have done the best job addressing this head on have had a very diverse set of voices around the table. And I think that is always the strategy I recommend, because that's the only one I've seen consistently work. AUDIENCE: Cool, thank you. JORGE CUETO: We're on time now. But if you can do these last three questions quickly, we can get through them. SAM ALTMAN: Sure. AUDIENCE: Thank you for coming, Sam. My question is on machine learning and artificial intelligence companies. It seems to me that the scarce or valuable thing is data in those areas and less so the algorithm, because they're mostly open source. So I was wondering how you think about that when getting pitches from companies. SAM ALTMAN: I used to believe that. I now believe that it's going to be compute, not data. I think data is important, but there will be a lot of it available. And just my own experience with OpenAI, to really be at the forefront here, you just need massive amounts of compute. And so I used to ask companies how they're going to get a lot of data. Now, I ask them how they're going to get a lot of compute. AUDIENCE: OK. Thank you. SAM ALTMAN: Sure. AUDIENCE: Hey, Sam. Thanks for coming. I know you were talking about people are becoming unhappier and the world [INAUDIBLE] problem, all these kind of things that are kind of quantifiable, like physical needs of people. Have you or had companies that come to you kind of try to solve the spiritual needs of people? Because we can identify the physical needs, but what about like spiritual needs or research or companies? SAM ALTMAN: We have had a few. None of them have really worked yet. But you know, one that stuck out of memory was a company came to us and said, churches, you know, organized religion had this really important effect that was totally separate from the religion itself, which was this tight-knit community. And how do you build that in a world where most people or a declining number of people believe in religion and go to church? And so I think there are people thinking about things like that, which are sort of these non-obvious attacks on the problem that are interesting, but none that I could yet point to as here's this thing that's really worked well. AUDIENCE: Hey, Sam. So you partnered with the ACLU earlier this year, which you got mixed reactions to. I'm wondering what you learned from that whole experience, what successes you've had, and what partnerships you're looking forward to with other non-profits in the future? SAM ALTMAN: I was really excited about how that went. We had never done anything like that before. We often try new things. Usually, they don't work. Sometimes they do. That's something we would do again. We would do something more like that. I think there are these really important organizations in the world that can use our help to build better technology teams. And that was an experiment that went well and that we'd love to try again. One of our software engineers, [INAUDIBLE],, went there for-- I think she went for like eight weeks, almost the whole program, sat in their offices, helped them. We got a call from them later about how well it went, being able to help them, you know, expand and supplement their team. And you know, I think that's something we'd like to try again. JORGE CUETO: And one last question, because it's gotten so many votes. SAM ALTMAN: Sure. JORGE CUETO: Elon Musk recently called for preemptive AI regulation at the National Governors Association. As a chair of OpenAI and friend of Musk's, what is your opinion on this issue? And what specific actions can we take to minimize future risk? SAM ALTMAN: The specific thing I would support today is just insight. I think the government should understand where the edge of capabilities are and how it's evolving. Because I think no one, certainly not the government, knows what the regulation for AI should look like today. But I'd be in favor of starting that education process. JORGE CUETO: Awesome. So, yeah, that was our last question. SAM ALTMAN: Thank you all. JORGE CUETO: Thank you, everyone, for coming. SAM ALTMAN: Thanks for having me." \
           ""

import re # word searching in text
from nltk.corpus import stopwords # removes meaningless words such as the, and......
from nltk.stem.porter import PorterStemmer # finds the root word
import nltk
nltk.download('stopwords')
port_stem = PorterStemmer()
def stemming(content):
    stemmed_content = re.sub('[^a-zA-Z]', ' ', content) # collect all alphabets only
    stemmed_content = stemmed_content.lower() # lower case text
    stemmed_content = stemmed_content.split() #split into list
    stemmed_content = [port_stem.stem(word) for word in stemmed_content if not word in stopwords.words('english')] # converting words into root words
    stemmed_content = ' '.join(stemmed_content)
    return stemmed_content
stemmed_data_set = stemming(data_set)
print(stemmed_data_set)


# Python program to find the k most frequent words
# from data set
# split() returns list of all the words in the string
stemmed_data_set = stemmed_data_set.split()

# Pass the split_it list to instance of Counter class.
Counter = Counter(stemmed_data_set)

# most_common() produces k frequently encountered
# input values and their respective counts.
most_occur = Counter.most_common(40)
print(most_occur)

# Python3 code to demonstrate working of average word length
test_list = stemmed_data_set
temp = [len(ele) for ele in test_list]
res = 0 if len(temp) == 0 else (float(sum(temp)) / len(temp))
# printing result
print("The Average length of String in list is : " + str(res))
